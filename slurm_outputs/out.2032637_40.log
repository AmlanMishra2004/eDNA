SLURM_JOB_ID: 2032637
SLURM_ARRAY_JOB_ID: 2032637
SLURM_ARRAY_TASK_ID: 40
SLURM_ARRAY_TASK_COUNT: 40
SLURM_ARRAY_TASK_MAX: 40
SLURM_ARRAY_TASK_MIN: 1
===========================================
/home/swaggoner/eDNA/protopnet
grtx-1.cluster
Fri Sep  6 01:10:10 EDT 2024
===========================================
13:4: not a valid test operator: (
13:4: not a valid test operator: 525.85.12

=============
== PyTorch ==
=============

NVIDIA Release 23.09 (build 69180607)
PyTorch Version 2.1.0a0+32f93b1

Container image Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.

Copyright (c) 2014-2023 Facebook Inc.
Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)
Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)
Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)
Copyright (c) 2011-2013 NYU                      (Clement Farabet)
Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)
Copyright (c) 2006      Idiap Research Institute (Samy Bengio)
Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)
Copyright (c) 2015      Google Inc.
Copyright (c) 2015      Yangqing Jia
Copyright (c) 2013-2016 The Caffe contributors
All rights reserved.

Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

WARNING: CUDA Minor Version Compatibility mode ENABLED.
  Using driver version 525.85.12 which has support for CUDA 12.0.  This container
  was built with CUDA 12.2 and will be run in Minor Version Compatibility mode.
  CUDA Forward Compatibility is preferred over Minor Version Compatibility for use
  with this container but was unavailable:
  [[]]
  See https://docs.nvidia.com/deploy/cuda-compatibility/ for details.

NOTE: Mellanox network driver detected, but NVIDIA peer memory driver not
      detected.  Multi-node communication performance may be reduced.

2024-09-06 01:10:27.960543: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.
2024-09-06 01:10:28.561219: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-09-06 01:10:28.561285: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-09-06 01:10:28.564317: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-09-06 01:10:28.936143: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
Available CUDA devices: 0
comb_num: 40
arr_job_id: 2032637
job_id: -1

Training on train_noise 1 and test_noise 0
Training on ../datasets/train_same_as_zurich_oversampled_t70_noise-0_thresh-2.csv
Testing on ../datasets/test_same_as_zurich_t70_noise-0_thresh-2.csv
testRandomInsertions: [0, 0]
testRandomDeletions: [0, 0]
testMutationRate: 0
trainRandomInsertions: [0, 2]
trainRandomDeletions: [0, 2]
trainMutationRate: 0.05
All classes in the test set are present in the training set.
Before oversampling:
------------------------------------------------------------
Number of sequences:                                      780
Number of distinct species_cat                            156
Average number of sequences per species_cat             5.00
Range in the number of sequences per species_cat           0
------------------------------------------------------------
Oversampled shape: (780, 10)


Trial 1

training set size: 780
push set size: 936
test set size: 175
train batch size: 156
test batch size: 35
Hyperparameters: {'prototype_shape': [(468, 520, 5)], 'latent_weight': [0.7], 'num_warm_epochs': [80, 65, 50, 35, 20], 'push_start': [20], 'push_gap': [15], 'num_pushes': [4], 'crs_ent_weight': [1], 'clst_weight': [-1], 'sep_weight': [0.3], 'l1_weight': [0.0001], 'p0_warm_ptype_lr': [0.05], 'p0_warm_ptype_gamma': [0.75], 'p0_warm_ptype_step_size': [125], 'p1_last_layer_lr': [0.001], 'p1_last_layer_iterations': [15], 'p1_warm_ptype_lr': [0.05], 'p1_warm_ptype_gamma': [0.9], 'p1_warm_ptype_step_size': [50], 'p2_last_layer_lr': [0.008], 'p2_last_layer_iterations': [20], 'p2_warm_ptype_lr': [0.05], 'p2_warm_ptype_gamma': [0.9], 'p2_warm_ptype_step_size': [50], 'p3_last_layer_lr': [0.01], 'p3_last_layer_iterations': [20], 'p3_warm_ptype_lr': [0.025], 'p3_warm_ptype_gamma': [0.9], 'p3_warm_ptype_step_size': [50], 'p4_last_layer_lr': [0.0005], 'p4_last_layer_iterations': [20], 'p4_warm_ptype_lr': [0.02], 'p4_warm_ptype_gamma': [0.9], 'p4_warm_ptype_step_size': [50], 'p5_last_layer_lr': [0.0001], 'p5_last_layer_iterations': [15], 'joint_weight_decay': [5e-06], 'joint_lr_step_size': [5, 10], 'joint_gamma': [0.7], 'joint_feature_lr': [0.0001, 0.001], 'joint_ptype_lr': [0.01, 0.001]}


Checking hyperparameters: {'num_warm_epochs': [80, 65, 50, 35, 20], 'joint_lr_step_size': [5, 10], 'joint_feature_lr': [0.0001, 0.001], 'joint_ptype_lr': [0.01, 0.001]}


Performing combination number 40 trial 0


Exploring 40 hyperparameter combination(s) for grid search.


Attempting combination 40/40:
prototype_shape: (468, 520, 5)
latent_weight: 0.7
num_warm_epochs: 20
push_start: 20
push_gap: 15
num_pushes: 4
crs_ent_weight: 1
clst_weight: -1
sep_weight: 0.3
l1_weight: 0.0001
p0_warm_ptype_lr: 0.05
p0_warm_ptype_gamma: 0.75
p0_warm_ptype_step_size: 125
p1_last_layer_lr: 0.001
p1_last_layer_iterations: 15
p1_warm_ptype_lr: 0.05
p1_warm_ptype_gamma: 0.9
p1_warm_ptype_step_size: 50
p2_last_layer_lr: 0.008
p2_last_layer_iterations: 20
p2_warm_ptype_lr: 0.05
p2_warm_ptype_gamma: 0.9
p2_warm_ptype_step_size: 50
p3_last_layer_lr: 0.01
p3_last_layer_iterations: 20
p3_warm_ptype_lr: 0.025
p3_warm_ptype_gamma: 0.9
p3_warm_ptype_step_size: 50
p4_last_layer_lr: 0.0005
p4_last_layer_iterations: 20
p4_warm_ptype_lr: 0.02
p4_warm_ptype_gamma: 0.9
p4_warm_ptype_step_size: 50
p5_last_layer_lr: 0.0001
p5_last_layer_iterations: 15
joint_weight_decay: 5e-06
joint_lr_step_size: 10
joint_gamma: 0.7
joint_feature_lr: 0.001
joint_ptype_lr: 0.001



End epoch: 79
Val acc before epoch 0: 0.007142857142857143
Warm optimizer lr: 0.05
Val acc before epoch 1: 0.11428571428571428
Warm optimizer lr: 0.05
Val acc before epoch 2: 0.25
Warm optimizer lr: 0.05
Val acc before epoch 3: 0.37142857142857144
Warm optimizer lr: 0.05
Val acc before epoch 4: 0.37857142857142856
Warm optimizer lr: 0.05
Val acc before epoch 5: 0.37142857142857144
Warm optimizer lr: 0.05
Val acc before epoch 6: 0.45
Warm optimizer lr: 0.05
Val acc before epoch 7: 0.5142857142857142
Warm optimizer lr: 0.05
Val acc before epoch 8: 0.6357142857142857
Warm optimizer lr: 0.05
Val acc before epoch 9: 0.7428571428571429
Warm optimizer lr: 0.05
Val acc before epoch 10: 0.7642857142857142
Warm optimizer lr: 0.05
Val acc before epoch 11: 0.8
Warm optimizer lr: 0.05
Val acc before epoch 12: 0.8
Warm optimizer lr: 0.05
Val acc before epoch 13: 0.8357142857142857
Warm optimizer lr: 0.05
Val acc before epoch 14: 0.85
Warm optimizer lr: 0.05
Val acc before epoch 15: 0.8642857142857143
Warm optimizer lr: 0.05
Val acc before epoch 16: 0.8785714285714286
Warm optimizer lr: 0.05
Val acc before epoch 17: 0.9
Warm optimizer lr: 0.05
Val acc before epoch 18: 0.8785714285714286
Warm optimizer lr: 0.05
Val acc before epoch 19: 0.8928571428571429
Warm optimizer lr: 0.05
Val acc before epoch 20: 0.8857142857142857
Push epoch at epoch 21.
Final validation accuracy before push 1: 0.8857142857142857
Push number 1












After push, before retraining last layer:
	Train acc: 0.5592948717948718
	Train Cluster: 0.8628118157386779
	Train Separation: 0.914091944694519
(Directly after push 1) Val acc at iteration 0: 0.8785714285714286
Retraining last layer: 
Last layer lr: 0.001
	Val acc at iteration 0: 0.8357142857142857
	Val acc at iteration 1: 0.8857142857142857
	Val acc at iteration 2: 0.9285714285714286
	Val acc at iteration 3: 0.9285714285714286
	Val acc at iteration 4: 0.9357142857142857
	Val acc at iteration 5: 0.9142857142857143
	Val acc at iteration 6: 0.9428571428571428
	Val acc at iteration 7: 0.9285714285714286
	Val acc at iteration 8: 0.95
	Val acc at iteration 9: 0.9428571428571428
	Val acc at iteration 10: 0.95
	Val acc at iteration 11: 0.9428571428571428
	Val acc at iteration 12: 0.9428571428571428
	Val acc at iteration 13: 0.95
	Val acc at iteration 14: 0.95
Val acc before epoch 21: 0.95
Joint optimizer lr: 0.001
Joint optimizer lr: 0.001
Val acc before epoch 22: 0.95
Joint optimizer lr: 0.0007
Joint optimizer lr: 0.0007
Val acc before epoch 23: 0.9571428571428572
Joint optimizer lr: 0.0007
Joint optimizer lr: 0.0007
Val acc before epoch 24: 0.9571428571428572
Joint optimizer lr: 0.00049
Joint optimizer lr: 0.00049
Val acc before epoch 25: 0.9571428571428572
Joint optimizer lr: 0.00049
Joint optimizer lr: 0.00049
Val acc before epoch 26: 0.9571428571428572
Joint optimizer lr: 0.000343
Joint optimizer lr: 0.000343
Val acc before epoch 27: 0.9571428571428572
Joint optimizer lr: 0.000343
Joint optimizer lr: 0.000343
Val acc before epoch 28: 0.95
Joint optimizer lr: 0.00024009999999999998
Joint optimizer lr: 0.00024009999999999998
Val acc before epoch 29: 0.95
Joint optimizer lr: 0.00024009999999999998
Joint optimizer lr: 0.00024009999999999998
Val acc before epoch 30: 0.95
Joint optimizer lr: 0.00016806999999999998
Joint optimizer lr: 0.00016806999999999998
Val acc before epoch 31: 0.95
Joint optimizer lr: 0.00016806999999999998
Joint optimizer lr: 0.00016806999999999998
Val acc before epoch 32: 0.95
Joint optimizer lr: 0.00011764899999999998
Joint optimizer lr: 0.00011764899999999998
Val acc before epoch 33: 0.95
Joint optimizer lr: 0.00011764899999999998
Joint optimizer lr: 0.00011764899999999998
Val acc before epoch 34: 0.95
Joint optimizer lr: 8.235429999999999e-05
Joint optimizer lr: 8.235429999999999e-05
Val acc before epoch 35: 0.95
Push epoch at epoch 36.
Final validation accuracy before push 2: 0.95
Push number 2












After push, before retraining last layer:
	Train acc: 0.6618589743589743
	Train Cluster: 0.8650159716606141
	Train Separation: 0.9093461871147156
(Directly after push 2) Val acc at iteration 0: 0.95
Retraining last layer: 
Last layer lr: 0.008
	Val acc at iteration 0: 0.9357142857142857
	Val acc at iteration 1: 0.9214285714285714
	Val acc at iteration 2: 0.9428571428571428
	Val acc at iteration 3: 0.9357142857142857
	Val acc at iteration 4: 0.9428571428571428
	Val acc at iteration 5: 0.9071428571428571
	Val acc at iteration 6: 0.9285714285714286
	Val acc at iteration 7: 0.9428571428571428
	Val acc at iteration 8: 0.9428571428571428
	Val acc at iteration 9: 0.95
	Val acc at iteration 10: 0.95
	Val acc at iteration 11: 0.9285714285714286
	Val acc at iteration 12: 0.9571428571428572
	Val acc at iteration 13: 0.9357142857142857
	Val acc at iteration 14: 0.9428571428571428
	Val acc at iteration 15: 0.9642857142857143
	Val acc at iteration 16: 0.9428571428571428
	Val acc at iteration 17: 0.9428571428571428
	Val acc at iteration 18: 0.95
	Val acc at iteration 19: 0.9714285714285714
Val acc before epoch 36: 0.9714285714285714
Joint optimizer lr: 8.235429999999999e-05
Joint optimizer lr: 8.235429999999999e-05
Val acc before epoch 37: 0.9714285714285714
Joint optimizer lr: 5.764800999999999e-05
Joint optimizer lr: 5.764800999999999e-05
Val acc before epoch 38: 0.9714285714285714
Joint optimizer lr: 5.764800999999999e-05
Joint optimizer lr: 5.764800999999999e-05
Val acc before epoch 39: 0.9714285714285714
Joint optimizer lr: 4.035360699999999e-05
Joint optimizer lr: 4.035360699999999e-05
Val acc before epoch 40: 0.9714285714285714
Joint optimizer lr: 4.035360699999999e-05
Joint optimizer lr: 4.035360699999999e-05
Val acc before epoch 41: 0.9714285714285714
Joint optimizer lr: 2.8247524899999994e-05
Joint optimizer lr: 2.8247524899999994e-05
Val acc before epoch 42: 0.9714285714285714
Joint optimizer lr: 2.8247524899999994e-05
Joint optimizer lr: 2.8247524899999994e-05
Val acc before epoch 43: 0.9714285714285714
Joint optimizer lr: 1.9773267429999995e-05
Joint optimizer lr: 1.9773267429999995e-05
Val acc before epoch 44: 0.9714285714285714
Joint optimizer lr: 1.9773267429999995e-05
Joint optimizer lr: 1.9773267429999995e-05
Val acc before epoch 45: 0.9714285714285714
Joint optimizer lr: 1.3841287200999995e-05
Joint optimizer lr: 1.3841287200999995e-05
Val acc before epoch 46: 0.9714285714285714
Joint optimizer lr: 1.3841287200999995e-05
Joint optimizer lr: 1.3841287200999995e-05
Val acc before epoch 47: 0.9714285714285714
Joint optimizer lr: 9.688901040699997e-06
Joint optimizer lr: 9.688901040699997e-06
Val acc before epoch 48: 0.9714285714285714
Joint optimizer lr: 9.688901040699997e-06
Joint optimizer lr: 9.688901040699997e-06
Val acc before epoch 49: 0.9714285714285714
Joint optimizer lr: 6.782230728489997e-06
Joint optimizer lr: 6.782230728489997e-06
Val acc before epoch 50: 0.9714285714285714
Push epoch at epoch 51.
Final validation accuracy before push 3: 0.9714285714285714
Push number 3












After push, before retraining last layer:
	Train acc: 0.8012820512820513
	Train Cluster: 0.859360420703888
	Train Separation: 0.9080757737159729
(Directly after push 3) Val acc at iteration 0: 0.9714285714285714
Retraining last layer: 
Last layer lr: 0.01
	Val acc at iteration 0: 0.9571428571428572
	Val acc at iteration 1: 0.95
	Val acc at iteration 2: 0.9571428571428572
	Val acc at iteration 3: 0.95
	Val acc at iteration 4: 0.9714285714285714
	Val acc at iteration 5: 0.9571428571428572
	Val acc at iteration 6: 0.9571428571428572
	Val acc at iteration 7: 0.9714285714285714
	Val acc at iteration 8: 0.9642857142857143
	Val acc at iteration 9: 0.9785714285714285
	Val acc at iteration 10: 0.9714285714285714
	Val acc at iteration 11: 0.9785714285714285
	Val acc at iteration 12: 0.9928571428571429
	Val acc at iteration 13: 0.9857142857142858
	Val acc at iteration 14: 0.9857142857142858
	Val acc at iteration 15: 0.9928571428571429
	Val acc at iteration 16: 0.9714285714285714
	Val acc at iteration 17: 0.9785714285714285
	Val acc at iteration 18: 0.9785714285714285
	Val acc at iteration 19: 0.9714285714285714
Val acc before epoch 51: 0.9714285714285714
Joint optimizer lr: 6.782230728489997e-06
Joint optimizer lr: 6.782230728489997e-06
Val acc before epoch 52: 0.9714285714285714
Joint optimizer lr: 4.747561509942998e-06
Joint optimizer lr: 4.747561509942998e-06
Val acc before epoch 53: 0.9714285714285714
Joint optimizer lr: 4.747561509942998e-06
Joint optimizer lr: 4.747561509942998e-06
Val acc before epoch 54: 0.9714285714285714
Joint optimizer lr: 3.323293056960098e-06
Joint optimizer lr: 3.323293056960098e-06
Val acc before epoch 55: 0.9714285714285714
Joint optimizer lr: 3.323293056960098e-06
Joint optimizer lr: 3.323293056960098e-06
Val acc before epoch 56: 0.9714285714285714
Joint optimizer lr: 2.3263051398720685e-06
Joint optimizer lr: 2.3263051398720685e-06
Val acc before epoch 57: 0.9714285714285714
Joint optimizer lr: 2.3263051398720685e-06
Joint optimizer lr: 2.3263051398720685e-06
Val acc before epoch 58: 0.9714285714285714
Joint optimizer lr: 1.6284135979104478e-06
Joint optimizer lr: 1.6284135979104478e-06
Val acc before epoch 59: 0.9714285714285714
Joint optimizer lr: 1.6284135979104478e-06
Joint optimizer lr: 1.6284135979104478e-06
Val acc before epoch 60: 0.9714285714285714
Joint optimizer lr: 1.1398895185373134e-06
Joint optimizer lr: 1.1398895185373134e-06
Val acc before epoch 61: 0.9714285714285714
Joint optimizer lr: 1.1398895185373134e-06
Joint optimizer lr: 1.1398895185373134e-06
Val acc before epoch 62: 0.9714285714285714
Joint optimizer lr: 7.979226629761193e-07
Joint optimizer lr: 7.979226629761193e-07
Val acc before epoch 63: 0.9714285714285714
Joint optimizer lr: 7.979226629761193e-07
Joint optimizer lr: 7.979226629761193e-07
Val acc before epoch 64: 0.9714285714285714
Joint optimizer lr: 5.585458640832835e-07
Joint optimizer lr: 5.585458640832835e-07
Val acc before epoch 65: 0.9714285714285714
Push epoch at epoch 66.
Final validation accuracy before push 4: 0.9714285714285714
Push number 4












After push, before retraining last layer:
	Train acc: 0.8878205128205128
	Train Cluster: 0.8608642220497131
	Train Separation: 0.9101216554641723
(Directly after push 4) Val acc at iteration 0: 0.9714285714285714
Retraining last layer: 
Last layer lr: 0.0005
	Val acc at iteration 0: 0.9714285714285714
	Val acc at iteration 1: 0.9714285714285714
	Val acc at iteration 2: 0.9785714285714285
	Val acc at iteration 3: 0.9928571428571429
	Val acc at iteration 4: 0.9928571428571429
	Val acc at iteration 5: 0.9928571428571429
	Val acc at iteration 6: 0.9928571428571429
	Val acc at iteration 7: 0.9928571428571429
	Val acc at iteration 8: 0.9928571428571429
	Val acc at iteration 9: 0.9928571428571429
	Val acc at iteration 10: 0.9928571428571429
	Val acc at iteration 11: 0.9928571428571429
	Val acc at iteration 12: 0.9928571428571429
	Val acc at iteration 13: 0.9928571428571429
	Val acc at iteration 14: 0.9928571428571429
	Val acc at iteration 15: 0.9928571428571429
	Val acc at iteration 16: 0.9928571428571429
	Val acc at iteration 17: 0.9928571428571429
	Val acc at iteration 18: 0.9928571428571429
	Val acc at iteration 19: 0.9928571428571429
Val acc before epoch 66: 0.9928571428571429
Joint optimizer lr: 5.585458640832835e-07
Joint optimizer lr: 5.585458640832835e-07
Val acc before epoch 67: 0.9928571428571429
Joint optimizer lr: 3.9098210485829847e-07
Joint optimizer lr: 3.9098210485829847e-07
Val acc before epoch 68: 0.9928571428571429
Joint optimizer lr: 3.9098210485829847e-07
Joint optimizer lr: 3.9098210485829847e-07
Val acc before epoch 69: 0.9928571428571429
Joint optimizer lr: 2.736874734008089e-07
Joint optimizer lr: 2.736874734008089e-07
Val acc before epoch 70: 0.9928571428571429
Joint optimizer lr: 2.736874734008089e-07
Joint optimizer lr: 2.736874734008089e-07
Val acc before epoch 71: 0.9928571428571429
Joint optimizer lr: 1.9158123138056623e-07
Joint optimizer lr: 1.9158123138056623e-07
Val acc before epoch 72: 0.9928571428571429
Joint optimizer lr: 1.9158123138056623e-07
Joint optimizer lr: 1.9158123138056623e-07
Val acc before epoch 73: 0.9928571428571429
Joint optimizer lr: 1.3410686196639635e-07
Joint optimizer lr: 1.3410686196639635e-07
Val acc before epoch 74: 0.9928571428571429
Joint optimizer lr: 1.3410686196639635e-07
Joint optimizer lr: 1.3410686196639635e-07
Val acc before epoch 75: 0.9928571428571429
Joint optimizer lr: 9.387480337647744e-08
Joint optimizer lr: 9.387480337647744e-08
Val acc before epoch 76: 0.9928571428571429
Joint optimizer lr: 9.387480337647744e-08
Joint optimizer lr: 9.387480337647744e-08
Val acc before epoch 77: 0.9928571428571429
Joint optimizer lr: 6.57123623635342e-08
Joint optimizer lr: 6.57123623635342e-08
Val acc before epoch 78: 0.9928571428571429
Joint optimizer lr: 6.57123623635342e-08
Joint optimizer lr: 6.57123623635342e-08
Val acc before epoch 79: 0.9928571428571429
Stopping after epoch 80.
Final validation accuracy before push 5: 0.9928571428571429






After push, before retraining last layer:
	Train acc: 0.9358974358974359
	Train Cluster: 0.8612246990203858
	TrainSeparation: 0.9066854953765869
(Directly after push 5) Val acc at iteration 0: 0.9928571428571429
Retraining last layer
Last layer lr: 0.0001
	Train acc at iteration 1: 0.9439102564102564
	Val acc at iteration 0: 0.9928571428571429
	Train acc at iteration 2: 0.9310897435897436
	Val acc at iteration 1: 0.9928571428571429
	Train acc at iteration 3: 0.9294871794871795
	Val acc at iteration 2: 0.9928571428571429
	Train acc at iteration 4: 0.9230769230769231
	Val acc at iteration 3: 0.9928571428571429
	Train acc at iteration 5: 0.9342948717948718
	Val acc at iteration 4: 0.9928571428571429
	Train acc at iteration 6: 0.9230769230769231
	Val acc at iteration 5: 0.9928571428571429
	Train acc at iteration 7: 0.9375
	Val acc at iteration 6: 0.9928571428571429
	Train acc at iteration 8: 0.9471153846153846
	Val acc at iteration 7: 0.9928571428571429
	Train acc at iteration 9: 0.9182692307692307
	Val acc at iteration 8: 0.9928571428571429
	Train acc at iteration 10: 0.8990384615384616
	Val acc at iteration 9: 0.9928571428571429
	Train acc at iteration 11: 0.9230769230769231
	Val acc at iteration 10: 0.9928571428571429
	Train acc at iteration 12: 0.9262820512820513
	Val acc at iteration 11: 0.9928571428571429
	Train acc at iteration 13: 0.9310897435897436
	Val acc at iteration 12: 0.9928571428571429
	Train acc at iteration 14: 0.9358974358974359
	Val acc at iteration 13: 0.9928571428571429
	Train acc at iteration 15: 0.9358974358974359
	Val acc at iteration 14: 0.9928571428571429
/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Getting final train, validation, and test accuracy after training.
Calculating metrics

Train Accuracy: 0.9179487179487179
 Train Precision: 0.9278235653235651
 Train Recall: 0.9179487179487179
 Train F1: 0.917202242202242

Validation Accuracy: 0.9935897435897436
 Validation Precision: 0.9903846153846154
 Validation Recall: 0.9935897435897436
 Validation F1: 0.9914529914529916

Test Accuracy: 0.9485714285714286
 Test Precision: 0.9241452991452991
 Test Recall: 0.9455128205128205
 Test F1: 0.9314102564102564


Trial 2

training set size: 780
push set size: 936
test set size: 175
train batch size: 156
test batch size: 35
Hyperparameters: {'prototype_shape': [(468, 520, 5)], 'latent_weight': [0.7], 'num_warm_epochs': [80, 65, 50, 35, 20], 'push_start': [20], 'push_gap': [15], 'num_pushes': [4], 'crs_ent_weight': [1], 'clst_weight': [-1], 'sep_weight': [0.3], 'l1_weight': [0.0001], 'p0_warm_ptype_lr': [0.05], 'p0_warm_ptype_gamma': [0.75], 'p0_warm_ptype_step_size': [125], 'p1_last_layer_lr': [0.001], 'p1_last_layer_iterations': [15], 'p1_warm_ptype_lr': [0.05], 'p1_warm_ptype_gamma': [0.9], 'p1_warm_ptype_step_size': [50], 'p2_last_layer_lr': [0.008], 'p2_last_layer_iterations': [20], 'p2_warm_ptype_lr': [0.05], 'p2_warm_ptype_gamma': [0.9], 'p2_warm_ptype_step_size': [50], 'p3_last_layer_lr': [0.01], 'p3_last_layer_iterations': [20], 'p3_warm_ptype_lr': [0.025], 'p3_warm_ptype_gamma': [0.9], 'p3_warm_ptype_step_size': [50], 'p4_last_layer_lr': [0.0005], 'p4_last_layer_iterations': [20], 'p4_warm_ptype_lr': [0.02], 'p4_warm_ptype_gamma': [0.9], 'p4_warm_ptype_step_size': [50], 'p5_last_layer_lr': [0.0001], 'p5_last_layer_iterations': [15], 'joint_weight_decay': [5e-06], 'joint_lr_step_size': [5, 10], 'joint_gamma': [0.7], 'joint_feature_lr': [0.0001, 0.001], 'joint_ptype_lr': [0.01, 0.001]}


Checking hyperparameters: {'num_warm_epochs': [80, 65, 50, 35, 20], 'joint_lr_step_size': [5, 10], 'joint_feature_lr': [0.0001, 0.001], 'joint_ptype_lr': [0.01, 0.001]}


Performing combination number 40 trial 1


Exploring 40 hyperparameter combination(s) for grid search.


Attempting combination 40/40:
prototype_shape: (468, 520, 5)
latent_weight: 0.7
num_warm_epochs: 20
push_start: 20
push_gap: 15
num_pushes: 4
crs_ent_weight: 1
clst_weight: -1
sep_weight: 0.3
l1_weight: 0.0001
p0_warm_ptype_lr: 0.05
p0_warm_ptype_gamma: 0.75
p0_warm_ptype_step_size: 125
p1_last_layer_lr: 0.001
p1_last_layer_iterations: 15
p1_warm_ptype_lr: 0.05
p1_warm_ptype_gamma: 0.9
p1_warm_ptype_step_size: 50
p2_last_layer_lr: 0.008
p2_last_layer_iterations: 20
p2_warm_ptype_lr: 0.05
p2_warm_ptype_gamma: 0.9
p2_warm_ptype_step_size: 50
p3_last_layer_lr: 0.01
p3_last_layer_iterations: 20
p3_warm_ptype_lr: 0.025
p3_warm_ptype_gamma: 0.9
p3_warm_ptype_step_size: 50
p4_last_layer_lr: 0.0005
p4_last_layer_iterations: 20
p4_warm_ptype_lr: 0.02
p4_warm_ptype_gamma: 0.9
p4_warm_ptype_step_size: 50
p5_last_layer_lr: 0.0001
p5_last_layer_iterations: 15
joint_weight_decay: 5e-06
joint_lr_step_size: 10
joint_gamma: 0.7
joint_feature_lr: 0.001
joint_ptype_lr: 0.001



End epoch: 79
Val acc before epoch 0: 0.014285714285714285
Warm optimizer lr: 0.05
Val acc before epoch 1: 0.07857142857142857
Warm optimizer lr: 0.05
Val acc before epoch 2: 0.20714285714285716
Warm optimizer lr: 0.05
Val acc before epoch 3: 0.25
Warm optimizer lr: 0.05
Val acc before epoch 4: 0.3357142857142857
Warm optimizer lr: 0.05
Val acc before epoch 5: 0.36428571428571427
Warm optimizer lr: 0.05
Val acc before epoch 6: 0.4714285714285714
Warm optimizer lr: 0.05
Val acc before epoch 7: 0.4857142857142857
Warm optimizer lr: 0.05
Val acc before epoch 8: 0.55
Warm optimizer lr: 0.05
Val acc before epoch 9: 0.5714285714285714
Warm optimizer lr: 0.05
Val acc before epoch 10: 0.6142857142857143
Warm optimizer lr: 0.05
Val acc before epoch 11: 0.6071428571428571
Warm optimizer lr: 0.05
Val acc before epoch 12: 0.65
Warm optimizer lr: 0.05
Val acc before epoch 13: 0.6571428571428571
Warm optimizer lr: 0.05
Val acc before epoch 14: 0.6785714285714286
Warm optimizer lr: 0.05
Val acc before epoch 15: 0.7214285714285714
Warm optimizer lr: 0.05
Val acc before epoch 16: 0.7642857142857142
Warm optimizer lr: 0.05
Val acc before epoch 17: 0.7714285714285715
Warm optimizer lr: 0.05
Val acc before epoch 18: 0.7857142857142857
Warm optimizer lr: 0.05
Val acc before epoch 19: 0.7785714285714286
Warm optimizer lr: 0.05
Val acc before epoch 20: 0.7928571428571428
Push epoch at epoch 21.
Final validation accuracy before push 1: 0.7928571428571428
Push number 1












After push, before retraining last layer:
	Train acc: 0.4983974358974359
	Train Cluster: 0.8611247539520264
	Train Separation: 0.9094194889068603
(Directly after push 1) Val acc at iteration 0: 0.85
Retraining last layer: 
Last layer lr: 0.001
	Val acc at iteration 0: 0.85
	Val acc at iteration 1: 0.8642857142857143
	Val acc at iteration 2: 0.8642857142857143
	Val acc at iteration 3: 0.8571428571428571
	Val acc at iteration 4: 0.8857142857142857
	Val acc at iteration 5: 0.8785714285714286
	Val acc at iteration 6: 0.8857142857142857
	Val acc at iteration 7: 0.8785714285714286
	Val acc at iteration 8: 0.8857142857142857
	Val acc at iteration 9: 0.8857142857142857
	Val acc at iteration 10: 0.8857142857142857
	Val acc at iteration 11: 0.8928571428571429
	Val acc at iteration 12: 0.9
	Val acc at iteration 13: 0.8928571428571429
	Val acc at iteration 14: 0.8928571428571429
Val acc before epoch 21: 0.8928571428571429
Joint optimizer lr: 0.001
Joint optimizer lr: 0.001
Val acc before epoch 22: 0.8928571428571429
Joint optimizer lr: 0.0007
Joint optimizer lr: 0.0007
Val acc before epoch 23: 0.8928571428571429
Joint optimizer lr: 0.0007
Joint optimizer lr: 0.0007
Val acc before epoch 24: 0.8928571428571429
Joint optimizer lr: 0.00049
Joint optimizer lr: 0.00049
Val acc before epoch 25: 0.9
Joint optimizer lr: 0.00049
Joint optimizer lr: 0.00049
Val acc before epoch 26: 0.9
Joint optimizer lr: 0.000343
Joint optimizer lr: 0.000343
Val acc before epoch 27: 0.9
Joint optimizer lr: 0.000343
Joint optimizer lr: 0.000343
Val acc before epoch 28: 0.9
Joint optimizer lr: 0.00024009999999999998
Joint optimizer lr: 0.00024009999999999998
Val acc before epoch 29: 0.9
Joint optimizer lr: 0.00024009999999999998
Joint optimizer lr: 0.00024009999999999998
Val acc before epoch 30: 0.9
Joint optimizer lr: 0.00016806999999999998
Joint optimizer lr: 0.00016806999999999998
Val acc before epoch 31: 0.9
Joint optimizer lr: 0.00016806999999999998
Joint optimizer lr: 0.00016806999999999998
Val acc before epoch 32: 0.9
Joint optimizer lr: 0.00011764899999999998
Joint optimizer lr: 0.00011764899999999998
Val acc before epoch 33: 0.9
Joint optimizer lr: 0.00011764899999999998
Joint optimizer lr: 0.00011764899999999998
Val acc before epoch 34: 0.9
Joint optimizer lr: 8.235429999999999e-05
Joint optimizer lr: 8.235429999999999e-05
Val acc before epoch 35: 0.9
Push epoch at epoch 36.
Final validation accuracy before push 2: 0.9
Push number 2












After push, before retraining last layer:
	Train acc: 0.6314102564102564
	Train Cluster: 0.8559666514396668
	Train Separation: 0.9053494334220886
(Directly after push 2) Val acc at iteration 0: 0.8928571428571429
Retraining last layer: 
Last layer lr: 0.008
	Val acc at iteration 0: 0.9
	Val acc at iteration 1: 0.8928571428571429
	Val acc at iteration 2: 0.8857142857142857
	Val acc at iteration 3: 0.8714285714285714
	Val acc at iteration 4: 0.8714285714285714
	Val acc at iteration 5: 0.9214285714285714
	Val acc at iteration 6: 0.8928571428571429
	Val acc at iteration 7: 0.9071428571428571
	Val acc at iteration 8: 0.9
	Val acc at iteration 9: 0.9071428571428571
	Val acc at iteration 10: 0.9285714285714286
	Val acc at iteration 11: 0.9142857142857143
	Val acc at iteration 12: 0.9214285714285714
	Val acc at iteration 13: 0.9285714285714286
	Val acc at iteration 14: 0.9571428571428572
	Val acc at iteration 15: 0.9714285714285714
	Val acc at iteration 16: 0.95
	Val acc at iteration 17: 0.9571428571428572
	Val acc at iteration 18: 0.9428571428571428
	Val acc at iteration 19: 0.95
Val acc before epoch 36: 0.95
Joint optimizer lr: 8.235429999999999e-05
Joint optimizer lr: 8.235429999999999e-05
Val acc before epoch 37: 0.95
Joint optimizer lr: 5.764800999999999e-05
Joint optimizer lr: 5.764800999999999e-05
Val acc before epoch 38: 0.95
Joint optimizer lr: 5.764800999999999e-05
Joint optimizer lr: 5.764800999999999e-05
Val acc before epoch 39: 0.95
Joint optimizer lr: 4.035360699999999e-05
Joint optimizer lr: 4.035360699999999e-05
Val acc before epoch 40: 0.95
Joint optimizer lr: 4.035360699999999e-05
Joint optimizer lr: 4.035360699999999e-05
Val acc before epoch 41: 0.95
Joint optimizer lr: 2.8247524899999994e-05
Joint optimizer lr: 2.8247524899999994e-05
Val acc before epoch 42: 0.95
Joint optimizer lr: 2.8247524899999994e-05
Joint optimizer lr: 2.8247524899999994e-05
Val acc before epoch 43: 0.95
Joint optimizer lr: 1.9773267429999995e-05
Joint optimizer lr: 1.9773267429999995e-05
Val acc before epoch 44: 0.95
Joint optimizer lr: 1.9773267429999995e-05
Joint optimizer lr: 1.9773267429999995e-05
Val acc before epoch 45: 0.95
Joint optimizer lr: 1.3841287200999995e-05
Joint optimizer lr: 1.3841287200999995e-05
Val acc before epoch 46: 0.95
Joint optimizer lr: 1.3841287200999995e-05
Joint optimizer lr: 1.3841287200999995e-05
Val acc before epoch 47: 0.95
Joint optimizer lr: 9.688901040699997e-06
Joint optimizer lr: 9.688901040699997e-06
Val acc before epoch 48: 0.95
Joint optimizer lr: 9.688901040699997e-06
Joint optimizer lr: 9.688901040699997e-06
Val acc before epoch 49: 0.95
Joint optimizer lr: 6.782230728489997e-06
Joint optimizer lr: 6.782230728489997e-06
Val acc before epoch 50: 0.95
Push epoch at epoch 51.
Final validation accuracy before push 3: 0.95
Push number 3












After push, before retraining last layer:
	Train acc: 0.8125
	Train Cluster: 0.863847303390503
	Train Separation: 0.9057414174079895
(Directly after push 3) Val acc at iteration 0: 0.95
Retraining last layer: 
Last layer lr: 0.01
	Val acc at iteration 0: 0.9642857142857143
	Val acc at iteration 1: 0.9642857142857143
	Val acc at iteration 2: 0.9642857142857143
	Val acc at iteration 3: 0.9428571428571428
	Val acc at iteration 4: 0.9714285714285714
	Val acc at iteration 5: 0.9428571428571428
	Val acc at iteration 6: 0.9642857142857143
	Val acc at iteration 7: 0.9642857142857143
	Val acc at iteration 8: 0.9642857142857143
	Val acc at iteration 9: 0.9571428571428572
	Val acc at iteration 10: 0.9714285714285714
	Val acc at iteration 11: 0.9571428571428572
	Val acc at iteration 12: 0.9642857142857143
	Val acc at iteration 13: 0.9714285714285714
	Val acc at iteration 14: 0.9714285714285714
	Val acc at iteration 15: 0.9642857142857143
	Val acc at iteration 16: 0.9857142857142858
	Val acc at iteration 17: 0.9785714285714285
	Val acc at iteration 18: 0.9785714285714285
	Val acc at iteration 19: 0.9857142857142858
Val acc before epoch 51: 0.9857142857142858
Joint optimizer lr: 6.782230728489997e-06
Joint optimizer lr: 6.782230728489997e-06
Val acc before epoch 52: 0.9857142857142858
Joint optimizer lr: 4.747561509942998e-06
Joint optimizer lr: 4.747561509942998e-06
Val acc before epoch 53: 0.9857142857142858
Joint optimizer lr: 4.747561509942998e-06
Joint optimizer lr: 4.747561509942998e-06
Val acc before epoch 54: 0.9857142857142858
Joint optimizer lr: 3.323293056960098e-06
Joint optimizer lr: 3.323293056960098e-06
Val acc before epoch 55: 0.9857142857142858
Joint optimizer lr: 3.323293056960098e-06
Joint optimizer lr: 3.323293056960098e-06
Val acc before epoch 56: 0.9857142857142858
Joint optimizer lr: 2.3263051398720685e-06
Joint optimizer lr: 2.3263051398720685e-06
Val acc before epoch 57: 0.9857142857142858
Joint optimizer lr: 2.3263051398720685e-06
Joint optimizer lr: 2.3263051398720685e-06
Val acc before epoch 58: 0.9857142857142858
Joint optimizer lr: 1.6284135979104478e-06
Joint optimizer lr: 1.6284135979104478e-06
Val acc before epoch 59: 0.9857142857142858
Joint optimizer lr: 1.6284135979104478e-06
Joint optimizer lr: 1.6284135979104478e-06
Val acc before epoch 60: 0.9857142857142858
Joint optimizer lr: 1.1398895185373134e-06
Joint optimizer lr: 1.1398895185373134e-06
Val acc before epoch 61: 0.9857142857142858
Joint optimizer lr: 1.1398895185373134e-06
Joint optimizer lr: 1.1398895185373134e-06
Val acc before epoch 62: 0.9857142857142858
Joint optimizer lr: 7.979226629761193e-07
Joint optimizer lr: 7.979226629761193e-07
Val acc before epoch 63: 0.9857142857142858
Joint optimizer lr: 7.979226629761193e-07
Joint optimizer lr: 7.979226629761193e-07
Val acc before epoch 64: 0.9857142857142858
Joint optimizer lr: 5.585458640832835e-07
Joint optimizer lr: 5.585458640832835e-07
Val acc before epoch 65: 0.9857142857142858
Push epoch at epoch 66.
Final validation accuracy before push 4: 0.9857142857142858
Push number 4












After push, before retraining last layer:
	Train acc: 0.9326923076923077
	Train Cluster: 0.8606547951698303
	Train Separation: 0.9136176466941833
(Directly after push 4) Val acc at iteration 0: 0.9857142857142858
Retraining last layer: 
Last layer lr: 0.0005
	Val acc at iteration 0: 0.9857142857142858
	Val acc at iteration 1: 0.9928571428571429
	Val acc at iteration 2: 0.9928571428571429
	Val acc at iteration 3: 0.9928571428571429
	Val acc at iteration 4: 0.9928571428571429
	Val acc at iteration 5: 0.9928571428571429
	Val acc at iteration 6: 0.9928571428571429
	Val acc at iteration 7: 0.9928571428571429
	Val acc at iteration 8: 0.9928571428571429
	Val acc at iteration 9: 0.9928571428571429
	Val acc at iteration 10: 0.9928571428571429
	Val acc at iteration 11: 0.9928571428571429
	Val acc at iteration 12: 0.9928571428571429
	Val acc at iteration 13: 0.9928571428571429
	Val acc at iteration 14: 0.9928571428571429
	Val acc at iteration 15: 0.9928571428571429
	Val acc at iteration 16: 0.9928571428571429
	Val acc at iteration 17: 0.9928571428571429
	Val acc at iteration 18: 0.9928571428571429
	Val acc at iteration 19: 0.9928571428571429
Val acc before epoch 66: 0.9928571428571429
Joint optimizer lr: 5.585458640832835e-07
Joint optimizer lr: 5.585458640832835e-07
Val acc before epoch 67: 0.9928571428571429
Joint optimizer lr: 3.9098210485829847e-07
Joint optimizer lr: 3.9098210485829847e-07
Val acc before epoch 68: 0.9928571428571429
Joint optimizer lr: 3.9098210485829847e-07
Joint optimizer lr: 3.9098210485829847e-07
Val acc before epoch 69: 0.9928571428571429
Joint optimizer lr: 2.736874734008089e-07
Joint optimizer lr: 2.736874734008089e-07
Val acc before epoch 70: 0.9928571428571429
Joint optimizer lr: 2.736874734008089e-07
Joint optimizer lr: 2.736874734008089e-07
Val acc before epoch 71: 0.9928571428571429
Joint optimizer lr: 1.9158123138056623e-07
Joint optimizer lr: 1.9158123138056623e-07
Val acc before epoch 72: 0.9928571428571429
Joint optimizer lr: 1.9158123138056623e-07
Joint optimizer lr: 1.9158123138056623e-07
Val acc before epoch 73: 0.9928571428571429
Joint optimizer lr: 1.3410686196639635e-07
Joint optimizer lr: 1.3410686196639635e-07
Val acc before epoch 74: 0.9928571428571429
Joint optimizer lr: 1.3410686196639635e-07
Joint optimizer lr: 1.3410686196639635e-07
Val acc before epoch 75: 0.9928571428571429
Joint optimizer lr: 9.387480337647744e-08
Joint optimizer lr: 9.387480337647744e-08
Val acc before epoch 76: 0.9928571428571429
Joint optimizer lr: 9.387480337647744e-08
Joint optimizer lr: 9.387480337647744e-08
Val acc before epoch 77: 0.9928571428571429
Joint optimizer lr: 6.57123623635342e-08
Joint optimizer lr: 6.57123623635342e-08
Val acc before epoch 78: 0.9928571428571429
Joint optimizer lr: 6.57123623635342e-08
Joint optimizer lr: 6.57123623635342e-08
Val acc before epoch 79: 0.9928571428571429
Stopping after epoch 80.
Final validation accuracy before push 5: 0.9928571428571429






After push, before retraining last layer:
	Train acc: 0.9342948717948718
	Train Cluster: 0.8620197534561157
	TrainSeparation: 0.905463969707489
(Directly after push 5) Val acc at iteration 0: 0.9928571428571429
Retraining last layer
Last layer lr: 0.0001
	Train acc at iteration 1: 0.9391025641025641
	Val acc at iteration 0: 0.9928571428571429
	Train acc at iteration 2: 0.9310897435897436
	Val acc at iteration 1: 0.9928571428571429
	Train acc at iteration 3: 0.9375
	Val acc at iteration 2: 0.9928571428571429
	Train acc at iteration 4: 0.9439102564102564
	Val acc at iteration 3: 0.9928571428571429
	Train acc at iteration 5: 0.9166666666666666
	Val acc at iteration 4: 0.9928571428571429
	Train acc at iteration 6: 0.9342948717948718
	Val acc at iteration 5: 0.9928571428571429
	Train acc at iteration 7: 0.9342948717948718
	Val acc at iteration 6: 0.9928571428571429
	Train acc at iteration 8: 0.9230769230769231
	Val acc at iteration 7: 0.9928571428571429
	Train acc at iteration 9: 0.9246794871794872
	Val acc at iteration 8: 0.9928571428571429
	Train acc at iteration 10: 0.9214743589743589
	Val acc at iteration 9: 0.9928571428571429
	Train acc at iteration 11: 0.9455128205128205
	Val acc at iteration 10: 0.9928571428571429
	Train acc at iteration 12: 0.9182692307692307
	Val acc at iteration 11: 0.9928571428571429
	Train acc at iteration 13: 0.9391025641025641
	Val acc at iteration 12: 0.9928571428571429
	Train acc at iteration 14: 0.9230769230769231
	Val acc at iteration 13: 0.9928571428571429
	Train acc at iteration 15: 0.9358974358974359
	Val acc at iteration 14: 0.9928571428571429
/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Getting final train, validation, and test accuracy after training.
Calculating metrics

Train Accuracy: 0.9320512820512821
 Train Precision: 0.9421219983719984
 Train Recall: 0.932051282051282
 Train F1: 0.9309313549698164

Validation Accuracy: 0.9935897435897436
 Validation Precision: 0.9903846153846154
 Validation Recall: 0.9935897435897436
 Validation F1: 0.9914529914529916

Test Accuracy: 0.9485714285714286
 Test Precision: 0.9294871794871795
 Test Recall: 0.9455128205128205
 Test F1: 0.9348290598290597
Test accuracies: [0.9935897435897436, 0.9935897435897436]
Test accuracies: [0.9485714285714286, 0.9485714285714286]
Over 2 trials for all 40 models evaluated in the grid search, got average validation accuracy: 0.9935897435897436, standard deviation: 0.0
Over 2 trials for all 40 models evaluated in the grid search, got average testing accuracy: 0.9485714285714286, standard deviation: 0.0
Finished search.
