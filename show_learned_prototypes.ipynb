{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script will get all of the saved prototypes for the final epoch of the chosen ppnet, and form a table with the following columns:\n",
    "| Class (Latin name of fish) | Prototype | Context | Original Sequence |\n",
    "|---------------------------|--------------|-------------|------------------|\n",
    "| manganais angularais      |(of length 10)|(of length ?)| (of length 70)   |\n",
    "|                           |              |         |                  |\n",
    "|                           |              |         |                  |\n",
    "\n",
    "Behind the scenes, this script\n",
    "- reads in .npy and outputs a .csv\n",
    "- translates one-hot A,G,T,C to characters\n",
    "- finds context given receptive field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_to_sequence(sequence_arr):\n",
    "    \"\"\"Converts an string of DNA bases to a 4 channel numpy array.\n",
    "\n",
    "    This function converts a 4 channel numpy array to a string of DNA bases,\n",
    "    with A -> channel 0, T -> channel 1, C -> channel 2, and G -> channel 3.\n",
    "    For probability mode, it uses fractional values for ambiguity codes.\n",
    "    For example, N would be encoded as [.25, .25, .25, .25] since N means that\n",
    "    the base could be either A, T, C, or G. A full list of these codes can be\n",
    "    found at the https://droog.gs.washington.edu/mdecode/images/iupac.html \n",
    "    or https://www.dnabaser.com/articles/IUPAC%20ambiguity%20codes.html.\n",
    "    If a character is not a member of the IUPAC ambiguity codes, then it will\n",
    "    be encoded as [0, 0, 0, 0]. (This is how padding bases are encoded.)\n",
    "\n",
    "    Args:\n",
    "       sequence_arr (numpy.ndarray): A 4 x str_len array where the associated bases are the\n",
    "            nth entries of every vector. For example,\n",
    "            array_to_sequencec([[1 0 0 0], [0 1 0 0], [0 0 0 1], [0 0 1 0]]) would return\n",
    "            'ATCG'\n",
    "\n",
    "    Returns:\n",
    "        sequence (str): A string of bases, e.g. 'AGTCCCTC'\n",
    "    \"\"\"\n",
    "    mapping_char_to_arr = {\n",
    "        'a':[1, 0, 0, 0],\n",
    "        't':[0, 1, 0, 0],\n",
    "        #'u':[0, 1, 0, 0], # u = t\n",
    "        'c':[0, 0, 1, 0],\n",
    "        'g':[0, 0, 0, 1],\n",
    "        # two options\n",
    "        'y':[0, 0.5, 0.5 ,0],\n",
    "        'r':[0.5, 0, 0, 0.5],\n",
    "        'w':[0.5, 0.5, 0, 0],\n",
    "        's':[0, 0, 0.5, 0.5],\n",
    "        'k':[0, 0.5, 0, 0.5],\n",
    "        'm':[0.5, 0, 0.5, 0],\n",
    "        # three options\n",
    "        'd':[1/3, 1/3, 0, 1/3],\n",
    "        'v':[1/3, 0, 1/3, 1/3],\n",
    "        'h':[1/3, 1/3, 1/3, 0],\n",
    "        'b':[0, 1/3, 1/3, 1/3],\n",
    "        # four options\n",
    "        'x':[0.25, 0.25, 0.25, 0.25],\n",
    "        'n':[0.25, 0.25, 0.25, 0.25]\n",
    "    }\n",
    "    # reverse the keys and values of the dict\n",
    "    mapping = {tuple(v): k for k, v in mapping_char_to_arr.items()}\n",
    "    mapping = defaultdict(lambda: 'N', mapping)\n",
    "    result = ''\n",
    "    for i in range(len(sequence_arr[0])):\n",
    "        vector = [sequence_arr[0][i],\n",
    "                  sequence_arr[1][i],\n",
    "                  sequence_arr[2][i],\n",
    "                  sequence_arr[3][i]]\n",
    "        result += mapping[tuple(vector)]\n",
    "    result = result.upper()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_context(full_str, sub_str):\n",
    "    \"\"\"\n",
    "    I have two strings. the second string is contained within the first string.\n",
    "    how can I get the 3 chars to the left of the second string in the first\n",
    "    string (if they exist), concatenated with the second string, concatenated\n",
    "    with the three chars to the right of the second string in the first string\n",
    "    (if they exist)\n",
    "    \"\"\"\n",
    "    idx = full_str.find(sub_str)\n",
    "    if idx == -1:\n",
    "        return None  # sub_str not found\n",
    "    # Get 3 chars to the left (if they exist)\n",
    "    left = full_str[max(0, idx-3):idx]\n",
    "    # Get 3 chars to the right (if they exist)\n",
    "    right = full_str[idx+len(sub_str):idx+len(sub_str)+3]\n",
    "    return left + sub_str + right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These two methods are now unnecessary since we can determinately get which\n",
    "# species the prototype was for just by looking at the species_cat of the \n",
    "# train set. The first three prototypes were learned for species cat 0, the\n",
    "# next 3 for species cat 1, the next 3 for species cat 2, and so on.\n",
    "def get_species_info_by_prototype(\n",
    "        sequence,\n",
    "        test_file = r\"C:\\Users\\Sam\\OneDrive\\Desktop\\eDNA\\datasets\\test_same_as_zurich.csv\",\n",
    "        train_file = r\"C:\\Users\\Sam\\OneDrive\\Desktop\\eDNA\\datasets\\train_oversampled_same_as_zurich.csv\",\n",
    "        ):\n",
    "    \"\"\"\n",
    "    Gets the species name, family, and order of any sequence that happens to\n",
    "    contain the given prototype. The species that has the most matching\n",
    "    sequences is returned.\n",
    "    \"\"\"\n",
    "    # Search the train set and the test set, since the sequence could have come\n",
    "    # from either one.\n",
    "    matches = pd.DataFrame(columns=[\"Species\", \"Family\", \"Order\"])\n",
    "    for file in (test_file, train_file):\n",
    "        df = pd.read_csv(file)\n",
    "        for row_idx in df.index:\n",
    "            row = df.loc[row_idx]\n",
    "            # print(seq)\n",
    "            # print(sequence)\n",
    "            # print()\n",
    "            if sequence.lower() in row[\"seq\"].lower(): # also true if equivalent\n",
    "                matches.loc[len(matches)] = [row[\"species\"], row[\"family\"], row[\"order\"]]\n",
    "                # return (row[\"species\"], row[\"family\"], row[\"order\"])\n",
    "    if len(matches) == 0:\n",
    "        return (\"not found\", \"not found\", \"not found\")\n",
    "    else:\n",
    "        most_matched_species = matches['Species'].mode()[0]\n",
    "        row = matches[matches['Species'] == most_matched_species].iloc[0]\n",
    "        return (row[\"Species\"], row[\"Family\"], row[\"Order\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These two methods are now unnecessary since we can determinately get which\n",
    "# species the prototype was for just by looking at the species_cat of the \n",
    "# train set. The first three prototypes were learned for species cat 0, the\n",
    "# next 3 for species cat 1, the next 3 for species cat 2, and so on.\n",
    "def strip_trailing_N(s):\n",
    "    return s.rstrip('N')\n",
    "\n",
    "def matching_chars(s1, s2):\n",
    "    s1, s2 = strip_trailing_N(s1), strip_trailing_N(s2)\n",
    "    return sum(a == b for a, b in zip(s1, s2))\n",
    "\n",
    "def most_similar_row(df, col, target):\n",
    "    # Remove trailing 'N' from the target string as well\n",
    "    target = strip_trailing_N(target)\n",
    "    scores = df[col].apply(lambda x: matching_chars(x, target))\n",
    "    print(scores)\n",
    "    return scores.idxmax()  # Returns the row index with the highest score\n",
    "\n",
    "def get_species_info_by_comparison(\n",
    "        sequence,\n",
    "        train_file = r\"C:\\Users\\Sam\\OneDrive\\Desktop\\eDNA\\datasets\\train_oversampled_same_as_zurich.csv\",\n",
    "        ):\n",
    "    \"\"\"\n",
    "    Gets the species name, family, and order of the sequence in the train set\n",
    "    that best matches the given sequence. Comparison is done by number\n",
    "    of matching bases.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(train_file)\n",
    "    df[\"seq\"] = df[\"seq\"].str.lower()\n",
    "    sequence = sequence.lower()\n",
    "    row_idx = most_similar_row(df, \"seq\", sequence)\n",
    "    row = df.loc[row_idx]\n",
    "    return (row[\"species\"], row[\"family\"], row[\"order\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 1. 0. 0. 0. 0. 1. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 1. 1. 1. 1. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "(4, 10)\n",
      "ACACCCCACA\n"
     ]
    }
   ],
   "source": [
    "# Folder of best prototypes:\n",
    "\n",
    "# activations: an array of 31 integers, since the prototype is compared at 31 locations\n",
    "# original: an array containing 4 arrays, each of length 70\n",
    "# patch: the 10 bases in the original sequence that are the prototype (since prototype length is 5, and there is a max pool that halves the input)\n",
    "path = r'C:\\Users\\Sam\\OneDrive\\Desktop\\eDNA\\protopnet\\saved_prototypes\\1892566_8_-1_latent_0.7\\epoch-214\\prototype_0_patch.npy'\n",
    "data = np.load(path)\n",
    "print(data)\n",
    "print(data.shape)\n",
    "print(array_to_sequence(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=[\"Species\", \"Genus\", \"Family\", \"Order\", \"Original_Sequence\", \"Learned_Prototype\", \"Receptive_Field\"])\n",
    "species_cat = 0\n",
    "counter = 0\n",
    "for ptype_num in range(215):\n",
    "    base_path = rf'C:\\Users\\Sam\\OneDrive\\Desktop\\eDNA\\protopnet\\saved_prototypes\\1892566_8_-1_latent_0.7\\epoch-214\\prototype_{ptype_num}_'\n",
    "    \n",
    "    orig_seq_path = base_path + 'original.npy'\n",
    "    activations_path = base_path + 'activations.npy'\n",
    "    patch_path = base_path + 'patch.npy'\n",
    "\n",
    "    try:\n",
    "        test = np.load(orig_seq_path)\n",
    "    except:\n",
    "        # Ignore prototypes that weren't saved I guess?\n",
    "        continue\n",
    "\n",
    "    orig_seq_arr = np.load(orig_seq_path)\n",
    "    orig_seq_str = array_to_sequence(orig_seq_arr)\n",
    "\n",
    "    patch_arr = np.load(patch_path)\n",
    "    patch_str = array_to_sequence(patch_arr)\n",
    "\n",
    "    receptive_field_str = extract_context(orig_seq_str, patch_str)\n",
    "\n",
    "    train_df = pd.read_csv(r\"C:\\Users\\Sam\\OneDrive\\Desktop\\eDNA\\datasets\\train_oversampled_same_as_zurich.csv\")\n",
    "    row = train_df[train_df['species_cat'] == species_cat].iloc[0]\n",
    "\n",
    "    # These two methods are now unnecessary since we can determinately get which\n",
    "    # species the prototype was for just by looking at the species_cat of the \n",
    "    # train set. The first three prototypes were learned for species cat 0, the\n",
    "    # next 3 for species cat 1, the next 3 for species cat 2, and so on.\n",
    "    # species_info = get_species_info_by_prototype(patch_str)\n",
    "    # species_info = get_species_info_by_comparison(orig_seq_str)\n",
    "\n",
    "    df.loc[len(df)] = [row[\"species\"], row[\"genus\"], row[\"family\"], row[\"order\"], orig_seq_str, patch_str, receptive_field_str]\n",
    "    # df.loc[len(df)] = [\"Salmo salar\", \"waggoner marshes\", \"first order\", orig_seq_str, patch_str, receptive_field_str]\n",
    "    counter += 1\n",
    "    if counter == 3:\n",
    "        counter = 0\n",
    "        species_cat += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"learned_prototypes.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Species also in maine dataset:  []\n"
     ]
    }
   ],
   "source": [
    "maine_species = pd.read_csv(r\"C:\\Users\\Sam\\OneDrive\\Desktop\\eDNA\\datasets\\all_data_maine.csv\")\n",
    "\n",
    "# Get boolean mask: True where df1['A'] values are in df2['B']\n",
    "mask = df['Species'].isin(maine_species['Species'])\n",
    "\n",
    "matches = df.loc[mask, 'Species'].unique()\n",
    "print(\"Species also in maine dataset: \", matches)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_py3120",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
