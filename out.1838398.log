===========================================
/home/swaggoner/eDNA
grtx-1.cluster
Sat Mar 23 09:51:04 EDT 2024
===========================================
13:4: not a valid test operator: (
13:4: not a valid test operator: 525.85.12

=============
== PyTorch ==
=============

NVIDIA Release 23.09 (build 69180607)
PyTorch Version 2.1.0a0+32f93b1

Container image Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.

Copyright (c) 2014-2023 Facebook Inc.
Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)
Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)
Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)
Copyright (c) 2011-2013 NYU                      (Clement Farabet)
Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)
Copyright (c) 2006      Idiap Research Institute (Samy Bengio)
Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)
Copyright (c) 2015      Google Inc.
Copyright (c) 2015      Yangqing Jia
Copyright (c) 2013-2016 The Caffe contributors
All rights reserved.

Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

WARNING: CUDA Minor Version Compatibility mode ENABLED.
  Using driver version 525.85.12 which has support for CUDA 12.0.  This container
  was built with CUDA 12.2 and will be run in Minor Version Compatibility mode.
  CUDA Forward Compatibility is preferred over Minor Version Compatibility for use
  with this container but was unavailable:
  [[]]
  See https://docs.nvidia.com/deploy/cuda-compatibility/ for details.

NOTE: Mellanox network driver detected, but NVIDIA peer memory driver not
      detected.  Multi-node communication performance may be reduced.

2024-03-23 09:51:16.745754: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.
2024-03-23 09:51:17.353017: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-03-23 09:51:17.357112: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-03-23 09:51:17.366017: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-03-23 09:51:17.724233: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
0
Oversampled shape: (748, 2)


Trial 1

training set size: 780
push set size: 748
test set size: 175
train batch size: 156
test batch size: 94


Exploring 6 hyperparameter combinations for grid search.


Attempting combination 0/6:
prototype_shape: (468, 520, 29)
latent_weight: 0.9
joint_weight_decay: -1
gamma: 0.8
warm_lr_step_size: 100
crs_ent_weight: 1
clst_weight: -9.600000000000001
sep_weight: 2.4
l1_weight: 0.001
warm_ptype_lr: 0.1
last_layer_lr: 0.5
num_warm_epochs: 1000000
push_gap: -1
push_start: 13
num_pushes: 0
last_layer_epochs: 150
joint_lr_step_size: -1
joint_optimizer_lrs: {'features': -1, 'prototype_vectors': -1}



End epoch: 13
Val acc before epoch 0: 0.010638297872340425
Warm optimizer lr: 0.1
Val acc before epoch 1: 0.46808510638297873
Warm optimizer lr: 0.1
Val acc before epoch 2: 0.6808510638297872
Warm optimizer lr: 0.1
Val acc before epoch 3: 0.8617021276595744
Warm optimizer lr: 0.1
Val acc before epoch 4: 0.851063829787234
Warm optimizer lr: 0.1
Val acc before epoch 5: 0.9042553191489362
Warm optimizer lr: 0.1
Val acc before epoch 6: 0.925531914893617
Warm optimizer lr: 0.1
Val acc before epoch 7: 0.9361702127659575
Warm optimizer lr: 0.1
Val acc before epoch 8: 0.9042553191489362
Warm optimizer lr: 0.1
Val acc before epoch 9: 0.925531914893617
Warm optimizer lr: 0.1
Val acc before epoch 10: 0.9468085106382979
Warm optimizer lr: 0.1
Val acc before epoch 11: 0.9468085106382979
Warm optimizer lr: 0.1
Val acc before epoch 12: 0.9574468085106383
Warm optimizer lr: 0.1
Val acc before epoch 13: 0.9574468085106383
Stopping after epoch 14.
Final validation accuracy before push: 95.74468085106383%
Pushing prototypes since finished training
Retraining last layer
	Train acc at iteration 0: 0.34455128205128205
	Train acc at iteration 1: 0.00641025641025641
	Train acc at iteration 2: 0.004807692307692308
	Train acc at iteration 3: 0.00641025641025641
	Train acc at iteration 4: 0.022435897435897436
	Train acc at iteration 5: 0.028846153846153848
	Train acc at iteration 6: 0.0625
	Train acc at iteration 7: 0.08012820512820513
	Train acc at iteration 8: 0.09134615384615384
	Train acc at iteration 9: 0.08173076923076923
	Train acc at iteration 10: 0.13141025641025642
	Train acc at iteration 11: 0.16506410256410256
	Train acc at iteration 12: 0.20512820512820512
	Train acc at iteration 13: 0.22115384615384615
	Train acc at iteration 14: 0.23076923076923078
	Train acc at iteration 15: 0.25
	Train acc at iteration 16: 0.2676282051282051
	Train acc at iteration 17: 0.22115384615384615
	Train acc at iteration 18: 0.26282051282051283
	Train acc at iteration 19: 0.3092948717948718
	Train acc at iteration 20: 0.24519230769230768
	Train acc at iteration 21: 0.23717948717948717
	Train acc at iteration 22: 0.3573717948717949
	Train acc at iteration 23: 0.29967948717948717
	Train acc at iteration 24: 0.33814102564102566
	Train acc at iteration 25: 0.34935897435897434
	Train acc at iteration 26: 0.22435897435897437
	Train acc at iteration 27: 0.33974358974358976
	Train acc at iteration 28: 0.36698717948717946
	Train acc at iteration 29: 0.296474358974359
	Train acc at iteration 30: 0.14262820512820512
	Train acc at iteration 31: 0.17307692307692307
	Train acc at iteration 32: 0.3141025641025641
	Train acc at iteration 33: 0.2644230769230769
	Train acc at iteration 34: 0.3301282051282051
	Train acc at iteration 35: 0.2708333333333333
	Train acc at iteration 36: 0.40064102564102566
	Train acc at iteration 37: 0.3189102564102564
	Train acc at iteration 38: 0.2948717948717949
	Train acc at iteration 39: 0.3317307692307692
	Train acc at iteration 40: 0.39903846153846156
	Train acc at iteration 41: 0.358974358974359
	Train acc at iteration 42: 0.34615384615384615
	Train acc at iteration 43: 0.4551282051282051
	Train acc at iteration 44: 0.5240384615384616
	Train acc at iteration 45: 0.375
	Train acc at iteration 46: 0.4775641025641026
	Train acc at iteration 47: 0.4198717948717949
	Train acc at iteration 48: 0.47115384615384615
	Train acc at iteration 49: 0.42788461538461536
	Train acc at iteration 50: 0.47115384615384615
	Train acc at iteration 51: 0.5496794871794872
	Train acc at iteration 52: 0.483974358974359
	Train acc at iteration 53: 0.5560897435897436
	Train acc at iteration 54: 0.4791666666666667
	Train acc at iteration 55: 0.5016025641025641
	Train acc at iteration 56: 0.5160256410256411
	Train acc at iteration 57: 0.46474358974358976
	Train acc at iteration 58: 0.592948717948718
	Train acc at iteration 59: 0.47435897435897434
	Train acc at iteration 60: 0.5016025641025641
	Train acc at iteration 61: 0.5625
	Train acc at iteration 62: 0.5721153846153846
	Train acc at iteration 63: 0.46314102564102566
	Train acc at iteration 64: 0.5416666666666666
	Train acc at iteration 65: 0.5432692307692307
	Train acc at iteration 66: 0.6474358974358975
	Train acc at iteration 67: 0.5480769230769231
	Train acc at iteration 68: 0.49198717948717946
	Train acc at iteration 69: 0.6458333333333334
	Train acc at iteration 70: 0.594551282051282
	Train acc at iteration 71: 0.5961538461538461
	Train acc at iteration 72: 0.6153846153846154
	Train acc at iteration 73: 0.5064102564102564
	Train acc at iteration 74: 0.5608974358974359
	Train acc at iteration 75: 0.6394230769230769
	Train acc at iteration 76: 0.6169871794871795
	Train acc at iteration 77: 0.6169871794871795
	Train acc at iteration 78: 0.6746794871794872
	Train acc at iteration 79: 0.6618589743589743
	Train acc at iteration 80: 0.6169871794871795
	Train acc at iteration 81: 0.6490384615384616
	Train acc at iteration 82: 0.6394230769230769
	Train acc at iteration 83: 0.6442307692307693
	Train acc at iteration 84: 0.7307692307692307
	Train acc at iteration 85: 0.5689102564102564
	Train acc at iteration 86: 0.7019230769230769
	Train acc at iteration 87: 0.7147435897435898
	Train acc at iteration 88: 0.6778846153846154
	Train acc at iteration 89: 0.625
	Train acc at iteration 90: 0.6955128205128205
	Train acc at iteration 91: 0.6939102564102564
	Train acc at iteration 92: 0.6410256410256411
	Train acc at iteration 93: 0.6891025641025641
	Train acc at iteration 94: 0.655448717948718
	Train acc at iteration 95: 0.7083333333333334
	Train acc at iteration 96: 0.6842948717948718
	Train acc at iteration 97: 0.6891025641025641
	Train acc at iteration 98: 0.7275641025641025
	Train acc at iteration 99: 0.7371794871794872
	Train acc at iteration 100: 0.7307692307692307
	Train acc at iteration 101: 0.6618589743589743
	Train acc at iteration 102: 0.7019230769230769
	Train acc at iteration 103: 0.7259615384615384
	Train acc at iteration 104: 0.6842948717948718
	Train acc at iteration 105: 0.7307692307692307
	Train acc at iteration 106: 0.7644230769230769
	Train acc at iteration 107: 0.6698717948717948
	Train acc at iteration 108: 0.7275641025641025
	Train acc at iteration 109: 0.7467948717948718
	Train acc at iteration 110: 0.7339743589743589
	Train acc at iteration 111: 0.7580128205128205
	Train acc at iteration 112: 0.7644230769230769
	Train acc at iteration 113: 0.7564102564102564
	Train acc at iteration 114: 0.7660256410256411
	Train acc at iteration 115: 0.7548076923076923
	Train acc at iteration 116: 0.717948717948718
	Train acc at iteration 117: 0.7644230769230769
	Train acc at iteration 118: 0.7467948717948718
	Train acc at iteration 119: 0.7548076923076923
	Train acc at iteration 120: 0.7371794871794872
	Train acc at iteration 121: 0.7035256410256411
	Train acc at iteration 122: 0.7516025641025641
	Train acc at iteration 123: 0.717948717948718
	Train acc at iteration 124: 0.7227564102564102
	Train acc at iteration 125: 0.6939102564102564
	Train acc at iteration 126: 0.7772435897435898
	Train acc at iteration 127: 0.7580128205128205
	Train acc at iteration 128: 0.7099358974358975
	Train acc at iteration 129: 0.7692307692307693
	Train acc at iteration 130: 0.7371794871794872
	Train acc at iteration 131: 0.7644230769230769
	Train acc at iteration 132: 0.7147435897435898
	Train acc at iteration 133: 0.7483974358974359
	Train acc at iteration 134: 0.7660256410256411
	Train acc at iteration 135: 0.7371794871794872
	Train acc at iteration 136: 0.7756410256410257
	Train acc at iteration 137: 0.7596153846153846
	Train acc at iteration 138: 0.7724358974358975
	Train acc at iteration 139: 0.717948717948718
	Train acc at iteration 140: 0.7676282051282052
	Train acc at iteration 141: 0.7612179487179487
	Train acc at iteration 142: 0.7019230769230769
	Train acc at iteration 143: 0.7339743589743589
	Train acc at iteration 144: 0.7451923076923077
	Train acc at iteration 145: 0.7259615384615384
	Train acc at iteration 146: 0.7451923076923077
	Train acc at iteration 147: 0.7628205128205128
	Train acc at iteration 148: 0.7339743589743589
	Train acc at iteration 149: 0.6907051282051282
Getting final validation and test accuracy after training.
Computing and storing results metrics
Final val macro f1-score: 0.5399999999999999
Final val micro accuracy: 0.6595744680851063
Final test macro f1-score: 0.48501872659176026
Final test micro accuracy: 0.5851063829787234
Final validation:
	Cluster: 0.6248303651809692
	Separation: 0.5347070097923279
Final test:
	Cluster: 0.6148161888122559
	Separation: 0.5359264612197876
Saved Results

Attempting combination 1/6:
prototype_shape: (468, 520, 29)
latent_weight: 0.9
joint_weight_decay: -1
gamma: 0.8
warm_lr_step_size: 100
crs_ent_weight: 1
clst_weight: -9.600000000000001
sep_weight: 2.4
l1_weight: 0.001
warm_ptype_lr: 0.1
last_layer_lr: 0.01
num_warm_epochs: 1000000
push_gap: -1
push_start: 13
num_pushes: 0
last_layer_epochs: 150
joint_lr_step_size: -1
joint_optimizer_lrs: {'features': -1, 'prototype_vectors': -1}



End epoch: 13
Val acc before epoch 0: 0.010638297872340425
Warm optimizer lr: 0.1
Val acc before epoch 1: 0.425531914893617
Warm optimizer lr: 0.1
Val acc before epoch 2: 0.7127659574468085
Warm optimizer lr: 0.1
Val acc before epoch 3: 0.851063829787234
Warm optimizer lr: 0.1
Val acc before epoch 4: 0.8191489361702128
Warm optimizer lr: 0.1
Val acc before epoch 5: 0.8723404255319149
Warm optimizer lr: 0.1
Val acc before epoch 6: 0.8936170212765957
Warm optimizer lr: 0.1
Val acc before epoch 7: 0.925531914893617
Warm optimizer lr: 0.1
Val acc before epoch 8: 0.925531914893617
Warm optimizer lr: 0.1
Val acc before epoch 9: 0.9148936170212766
Warm optimizer lr: 0.1
Val acc before epoch 10: 0.9042553191489362
Warm optimizer lr: 0.1
Val acc before epoch 11: 0.925531914893617
Warm optimizer lr: 0.1
Val acc before epoch 12: 0.9148936170212766
Warm optimizer lr: 0.1
Val acc before epoch 13: 0.9361702127659575
Stopping after epoch 14.
Final validation accuracy before push: 93.61702127659575%
Pushing prototypes since finished training
Retraining last layer
	Train acc at iteration 0: 0.46314102564102566
	Train acc at iteration 1: 0.5128205128205128
	Train acc at iteration 2: 0.5208333333333334
	Train acc at iteration 3: 0.5737179487179487
	Train acc at iteration 4: 0.5544871794871795
	Train acc at iteration 5: 0.6137820512820513
	Train acc at iteration 6: 0.6522435897435898
	Train acc at iteration 7: 0.6762820512820513
	Train acc at iteration 8: 0.6538461538461539
	Train acc at iteration 9: 0.6346153846153846
	Train acc at iteration 10: 0.6698717948717948
	Train acc at iteration 11: 0.7291666666666666
	Train acc at iteration 12: 0.6778846153846154
	Train acc at iteration 13: 0.6490384615384616
	Train acc at iteration 14: 0.6714743589743589
	Train acc at iteration 15: 0.6858974358974359
	Train acc at iteration 16: 0.6858974358974359
	Train acc at iteration 17: 0.6410256410256411
	Train acc at iteration 18: 0.6826923076923077
	Train acc at iteration 19: 0.6442307692307693
	Train acc at iteration 20: 0.6137820512820513
	Train acc at iteration 21: 0.6682692307692307
	Train acc at iteration 22: 0.6201923076923077
	Train acc at iteration 23: 0.6826923076923077
	Train acc at iteration 24: 0.5993589743589743
	Train acc at iteration 25: 0.655448717948718
	Train acc at iteration 26: 0.6474358974358975
	Train acc at iteration 27: 0.6923076923076923
	Train acc at iteration 28: 0.6987179487179487
	Train acc at iteration 29: 0.6538461538461539
	Train acc at iteration 30: 0.717948717948718
	Train acc at iteration 31: 0.7115384615384616
	Train acc at iteration 32: 0.6875
	Train acc at iteration 33: 0.7355769230769231
	Train acc at iteration 34: 0.7019230769230769
	Train acc at iteration 35: 0.7387820512820513
	Train acc at iteration 36: 0.75
	Train acc at iteration 37: 0.7387820512820513
	Train acc at iteration 38: 0.7339743589743589
	Train acc at iteration 39: 0.7323717948717948
	Train acc at iteration 40: 0.7564102564102564
	Train acc at iteration 41: 0.7227564102564102
	Train acc at iteration 42: 0.7564102564102564
	Train acc at iteration 43: 0.6714743589743589
	Train acc at iteration 44: 0.7355769230769231
	Train acc at iteration 45: 0.7323717948717948
	Train acc at iteration 46: 0.7083333333333334
	Train acc at iteration 47: 0.7243589743589743
	Train acc at iteration 48: 0.7467948717948718
	Train acc at iteration 49: 0.7756410256410257
	Train acc at iteration 50: 0.7387820512820513
	Train acc at iteration 51: 0.7548076923076923
	Train acc at iteration 52: 0.7403846153846154
	Train acc at iteration 53: 0.7355769230769231
	Train acc at iteration 54: 0.7483974358974359
	Train acc at iteration 55: 0.7307692307692307
	Train acc at iteration 56: 0.75
	Train acc at iteration 57: 0.7291666666666666
	Train acc at iteration 58: 0.7916666666666666
	Train acc at iteration 59: 0.7355769230769231
	Train acc at iteration 60: 0.7724358974358975
	Train acc at iteration 61: 0.780448717948718
	Train acc at iteration 62: 0.7772435897435898
	Train acc at iteration 63: 0.7740384615384616
	Train acc at iteration 64: 0.7548076923076923
	Train acc at iteration 65: 0.7692307692307693
	Train acc at iteration 66: 0.7852564102564102
	Train acc at iteration 67: 0.780448717948718
	Train acc at iteration 68: 0.7660256410256411
	Train acc at iteration 69: 0.7884615384615384
	Train acc at iteration 70: 0.7756410256410257
	Train acc at iteration 71: 0.7724358974358975
	Train acc at iteration 72: 0.7628205128205128
	Train acc at iteration 73: 0.8044871794871795
	Train acc at iteration 74: 0.7708333333333334
	Train acc at iteration 75: 0.7692307692307693
	Train acc at iteration 76: 0.782051282051282
	Train acc at iteration 77: 0.7724358974358975
	Train acc at iteration 78: 0.7852564102564102
	Train acc at iteration 79: 0.7676282051282052
	Train acc at iteration 80: 0.7788461538461539
	Train acc at iteration 81: 0.8173076923076923
	Train acc at iteration 82: 0.7884615384615384
	Train acc at iteration 83: 0.7916666666666666
	Train acc at iteration 84: 0.7884615384615384
	Train acc at iteration 85: 0.7948717948717948
	Train acc at iteration 86: 0.7756410256410257
	Train acc at iteration 87: 0.7676282051282052
	Train acc at iteration 88: 0.7756410256410257
	Train acc at iteration 89: 0.7724358974358975
	Train acc at iteration 90: 0.7724358974358975
	Train acc at iteration 91: 0.7532051282051282
	Train acc at iteration 92: 0.8108974358974359
	Train acc at iteration 93: 0.7836538461538461
	Train acc at iteration 94: 0.782051282051282
	Train acc at iteration 95: 0.8173076923076923
	Train acc at iteration 96: 0.8012820512820513
	Train acc at iteration 97: 0.7916666666666666
	Train acc at iteration 98: 0.8012820512820513
	Train acc at iteration 99: 0.8060897435897436
	Train acc at iteration 100: 0.8108974358974359
	Train acc at iteration 101: 0.780448717948718
	Train acc at iteration 102: 0.8028846153846154
	Train acc at iteration 103: 0.8141025641025641
	Train acc at iteration 104: 0.7900641025641025
	Train acc at iteration 105: 0.8028846153846154
	Train acc at iteration 106: 0.8237179487179487
	Train acc at iteration 107: 0.8125
	Train acc at iteration 108: 0.7964743589743589
	Train acc at iteration 109: 0.7932692307692307
	Train acc at iteration 110: 0.7724358974358975
	Train acc at iteration 111: 0.8092948717948718
	Train acc at iteration 112: 0.8076923076923077
	Train acc at iteration 113: 0.7884615384615384
	Train acc at iteration 114: 0.8141025641025641
	Train acc at iteration 115: 0.7916666666666666
	Train acc at iteration 116: 0.7884615384615384
	Train acc at iteration 117: 0.8108974358974359
	Train acc at iteration 118: 0.8237179487179487
	Train acc at iteration 119: 0.8028846153846154
	Train acc at iteration 120: 0.7884615384615384
	Train acc at iteration 121: 0.7948717948717948
	Train acc at iteration 122: 0.7676282051282052
	Train acc at iteration 123: 0.8092948717948718
	Train acc at iteration 124: 0.7932692307692307
	Train acc at iteration 125: 0.8060897435897436
	Train acc at iteration 126: 0.8173076923076923
	Train acc at iteration 127: 0.7916666666666666
	Train acc at iteration 128: 0.8060897435897436
	Train acc at iteration 129: 0.8012820512820513
	Train acc at iteration 130: 0.7884615384615384
	Train acc at iteration 131: 0.7660256410256411
	Train acc at iteration 132: 0.8189102564102564
	Train acc at iteration 133: 0.7884615384615384
	Train acc at iteration 134: 0.8333333333333334
	Train acc at iteration 135: 0.7756410256410257
	Train acc at iteration 136: 0.8269230769230769
	Train acc at iteration 137: 0.8125
	Train acc at iteration 138: 0.7948717948717948
	Train acc at iteration 139: 0.8012820512820513
	Train acc at iteration 140: 0.8044871794871795
	Train acc at iteration 141: 0.7980769230769231
	Train acc at iteration 142: 0.8461538461538461
	Train acc at iteration 143: 0.8157051282051282
	Train acc at iteration 144: 0.8349358974358975
	Train acc at iteration 145: 0.7964743589743589
	Train acc at iteration 146: 0.8092948717948718
	Train acc at iteration 147: 0.8205128205128205
	Train acc at iteration 148: 0.8173076923076923
	Train acc at iteration 149: 0.8253205128205128
Getting final validation and test accuracy after training.
Computing and storing results metrics
Final val macro f1-score: 0.6003401360544217
Final val micro accuracy: 0.7127659574468085
Final test macro f1-score: 0.41557971014492756
Final test micro accuracy: 0.5531914893617021
Final validation:
	Cluster: 0.6260797679424286
	Separation: 0.5308293700218201
Final test:
	Cluster: 0.596843421459198
	Separation: 0.5394986271858215
Saved Results

Attempting combination 2/6:
prototype_shape: (468, 520, 29)
latent_weight: 0.9
joint_weight_decay: -1
gamma: 0.8
warm_lr_step_size: 100
crs_ent_weight: 1
clst_weight: -9.600000000000001
sep_weight: 2.4
l1_weight: 0.001
warm_ptype_lr: 0.1
last_layer_lr: 0.05
num_warm_epochs: 1000000
push_gap: -1
push_start: 13
num_pushes: 0
last_layer_epochs: 150
joint_lr_step_size: -1
joint_optimizer_lrs: {'features': -1, 'prototype_vectors': -1}



End epoch: 13
Val acc before epoch 0: 0.010638297872340425
Warm optimizer lr: 0.1
Val acc before epoch 1: 0.3723404255319149
Warm optimizer lr: 0.1
Val acc before epoch 2: 0.6382978723404256
Warm optimizer lr: 0.1
Val acc before epoch 3: 0.7553191489361702
Warm optimizer lr: 0.1
Val acc before epoch 4: 0.8297872340425532
Warm optimizer lr: 0.1
Val acc before epoch 5: 0.8404255319148937
Warm optimizer lr: 0.1
Val acc before epoch 6: 0.8723404255319149
Warm optimizer lr: 0.1
Val acc before epoch 7: 0.925531914893617
Warm optimizer lr: 0.1
Val acc before epoch 8: 0.8829787234042553
Warm optimizer lr: 0.1
Val acc before epoch 9: 0.9042553191489362
Warm optimizer lr: 0.1
Val acc before epoch 10: 0.9574468085106383
Warm optimizer lr: 0.1
Val acc before epoch 11: 0.925531914893617
Warm optimizer lr: 0.1
Val acc before epoch 12: 0.9361702127659575
Warm optimizer lr: 0.1
Val acc before epoch 13: 0.9148936170212766
Stopping after epoch 14.
Final validation accuracy before push: 91.48936170212765%
Pushing prototypes since finished training
Retraining last layer
	Train acc at iteration 0: 0.3942307692307692
	Train acc at iteration 1: 0.08493589743589744
	Train acc at iteration 2: 0.11858974358974358
	Train acc at iteration 3: 0.1201923076923077
	Train acc at iteration 4: 0.18269230769230768
	Train acc at iteration 5: 0.15865384615384615
	Train acc at iteration 6: 0.11217948717948718
	Train acc at iteration 7: 0.23717948717948717
	Train acc at iteration 8: 0.2916666666666667
	Train acc at iteration 9: 0.3349358974358974
	Train acc at iteration 10: 0.33814102564102566
	Train acc at iteration 11: 0.35096153846153844
	Train acc at iteration 12: 0.4391025641025641
	Train acc at iteration 13: 0.38301282051282054
	Train acc at iteration 14: 0.5144230769230769
	Train acc at iteration 15: 0.4583333333333333
	Train acc at iteration 16: 0.4375
	Train acc at iteration 17: 0.45032051282051283
	Train acc at iteration 18: 0.4519230769230769
	Train acc at iteration 19: 0.4407051282051282
	Train acc at iteration 20: 0.4967948717948718
	Train acc at iteration 21: 0.5240384615384616
	Train acc at iteration 22: 0.483974358974359
	Train acc at iteration 23: 0.5400641025641025
	Train acc at iteration 24: 0.5016025641025641
	Train acc at iteration 25: 0.5448717948717948
	Train acc at iteration 26: 0.5608974358974359
	Train acc at iteration 27: 0.5528846153846154
	Train acc at iteration 28: 0.5480769230769231
	Train acc at iteration 29: 0.5625
	Train acc at iteration 30: 0.5737179487179487
	Train acc at iteration 31: 0.6169871794871795
	Train acc at iteration 32: 0.6089743589743589
	Train acc at iteration 33: 0.6330128205128205
	Train acc at iteration 34: 0.6314102564102564
	Train acc at iteration 35: 0.625
	Train acc at iteration 36: 0.6442307692307693
	Train acc at iteration 37: 0.6426282051282052
	Train acc at iteration 38: 0.6506410256410257
	Train acc at iteration 39: 0.6458333333333334
	Train acc at iteration 40: 0.6810897435897436
	Train acc at iteration 41: 0.6955128205128205
	Train acc at iteration 42: 0.6666666666666666
	Train acc at iteration 43: 0.7083333333333334
	Train acc at iteration 44: 0.7163461538461539
	Train acc at iteration 45: 0.6714743589743589
	Train acc at iteration 46: 0.6923076923076923
	Train acc at iteration 47: 0.7035256410256411
	Train acc at iteration 48: 0.6826923076923077
	Train acc at iteration 49: 0.7003205128205128
	Train acc at iteration 50: 0.7275641025641025
	Train acc at iteration 51: 0.6923076923076923
	Train acc at iteration 52: 0.6987179487179487
	Train acc at iteration 53: 0.6987179487179487
	Train acc at iteration 54: 0.6842948717948718
	Train acc at iteration 55: 0.6762820512820513
	Train acc at iteration 56: 0.7147435897435898
	Train acc at iteration 57: 0.7403846153846154
	Train acc at iteration 58: 0.7532051282051282
	Train acc at iteration 59: 0.7259615384615384
	Train acc at iteration 60: 0.7243589743589743
	Train acc at iteration 61: 0.7259615384615384
	Train acc at iteration 62: 0.7339743589743589
	Train acc at iteration 63: 0.7900641025641025
	Train acc at iteration 64: 0.7772435897435898
	Train acc at iteration 65: 0.7644230769230769
	Train acc at iteration 66: 0.7467948717948718
	Train acc at iteration 67: 0.7307692307692307
	Train acc at iteration 68: 0.7339743589743589
	Train acc at iteration 69: 0.7564102564102564
	Train acc at iteration 70: 0.7580128205128205
	Train acc at iteration 71: 0.7451923076923077
	Train acc at iteration 72: 0.7516025641025641
	Train acc at iteration 73: 0.7532051282051282
	Train acc at iteration 74: 0.7628205128205128
	Train acc at iteration 75: 0.7612179487179487
	Train acc at iteration 76: 0.7660256410256411
	Train acc at iteration 77: 0.7451923076923077
	Train acc at iteration 78: 0.7596153846153846
	Train acc at iteration 79: 0.7243589743589743
	Train acc at iteration 80: 0.7548076923076923
	Train acc at iteration 81: 0.7516025641025641
	Train acc at iteration 82: 0.782051282051282
	Train acc at iteration 83: 0.7900641025641025
	Train acc at iteration 84: 0.7580128205128205
	Train acc at iteration 85: 0.7596153846153846
	Train acc at iteration 86: 0.7580128205128205
	Train acc at iteration 87: 0.7516025641025641
	Train acc at iteration 88: 0.7948717948717948
	Train acc at iteration 89: 0.7516025641025641
	Train acc at iteration 90: 0.7724358974358975
	Train acc at iteration 91: 0.7596153846153846
	Train acc at iteration 92: 0.7660256410256411
	Train acc at iteration 93: 0.7724358974358975
	Train acc at iteration 94: 0.7692307692307693
	Train acc at iteration 95: 0.7628205128205128
	Train acc at iteration 96: 0.7516025641025641
	Train acc at iteration 97: 0.7836538461538461
	Train acc at iteration 98: 0.7772435897435898
	Train acc at iteration 99: 0.7692307692307693
	Train acc at iteration 100: 0.780448717948718
	Train acc at iteration 101: 0.7660256410256411
	Train acc at iteration 102: 0.7980769230769231
	Train acc at iteration 103: 0.7628205128205128
	Train acc at iteration 104: 0.7740384615384616
	Train acc at iteration 105: 0.7724358974358975
	Train acc at iteration 106: 0.7932692307692307
	Train acc at iteration 107: 0.782051282051282
	Train acc at iteration 108: 0.8076923076923077
	Train acc at iteration 109: 0.7932692307692307
	Train acc at iteration 110: 0.780448717948718
	Train acc at iteration 111: 0.7996794871794872
	Train acc at iteration 112: 0.780448717948718
	Train acc at iteration 113: 0.7756410256410257
	Train acc at iteration 114: 0.7740384615384616
	Train acc at iteration 115: 0.7852564102564102
	Train acc at iteration 116: 0.7548076923076923
	Train acc at iteration 117: 0.7692307692307693
	Train acc at iteration 118: 0.7884615384615384
	Train acc at iteration 119: 0.7948717948717948
	Train acc at iteration 120: 0.7964743589743589
	Train acc at iteration 121: 0.7932692307692307
	Train acc at iteration 122: 0.7964743589743589
	Train acc at iteration 123: 0.782051282051282
	Train acc at iteration 124: 0.7692307692307693
	Train acc at iteration 125: 0.8012820512820513
	Train acc at iteration 126: 0.7900641025641025
	Train acc at iteration 127: 0.8125
	Train acc at iteration 128: 0.7964743589743589
	Train acc at iteration 129: 0.8028846153846154
	Train acc at iteration 130: 0.7884615384615384
	Train acc at iteration 131: 0.8381410256410257
	Train acc at iteration 132: 0.7884615384615384
	Train acc at iteration 133: 0.7948717948717948
	Train acc at iteration 134: 0.7900641025641025
	Train acc at iteration 135: 0.7932692307692307
	Train acc at iteration 136: 0.8060897435897436
	Train acc at iteration 137: 0.8060897435897436
	Train acc at iteration 138: 0.7996794871794872
	Train acc at iteration 139: 0.7788461538461539
	Train acc at iteration 140: 0.8028846153846154
	Train acc at iteration 141: 0.8141025641025641
	Train acc at iteration 142: 0.8237179487179487
	Train acc at iteration 143: 0.7996794871794872
	Train acc at iteration 144: 0.8205128205128205
	Train acc at iteration 145: 0.8189102564102564
	Train acc at iteration 146: 0.7772435897435898
	Train acc at iteration 147: 0.7868589743589743
	Train acc at iteration 148: 0.8189102564102564
	Train acc at iteration 149: 0.8189102564102564
Getting final validation and test accuracy after training.
Computing and storing results metrics
Final val macro f1-score: 0.5755102040816327
Final val micro accuracy: 0.6702127659574468
Final test macro f1-score: 0.5114942528735632
Final test micro accuracy: 0.6276595744680851
Final validation:
	Cluster: 0.638444721698761
	Separation: 0.533968985080719
Final test:
	Cluster: 0.6117897927761078
	Separation: 0.5308550298213959
Saved Results

Attempting combination 3/6:
prototype_shape: (468, 520, 29)
latent_weight: 0.9
joint_weight_decay: -1
gamma: 0.8
warm_lr_step_size: 100
crs_ent_weight: 1
clst_weight: -9.600000000000001
sep_weight: 2.4
l1_weight: 0.001
warm_ptype_lr: 0.1
last_layer_lr: 0.01
num_warm_epochs: 1000000
push_gap: -1
push_start: 13
num_pushes: 0
last_layer_epochs: 150
joint_lr_step_size: -1
joint_optimizer_lrs: {'features': -1, 'prototype_vectors': -1}



End epoch: 13
Val acc before epoch 0: 0.010638297872340425
Warm optimizer lr: 0.1
Val acc before epoch 1: 0.44680851063829785
Warm optimizer lr: 0.1
Val acc before epoch 2: 0.6914893617021277
Warm optimizer lr: 0.1
Val acc before epoch 3: 0.776595744680851
Warm optimizer lr: 0.1
Val acc before epoch 4: 0.8297872340425532
Warm optimizer lr: 0.1
Val acc before epoch 5: 0.8617021276595744
Warm optimizer lr: 0.1
Val acc before epoch 6: 0.9042553191489362
Warm optimizer lr: 0.1
Val acc before epoch 7: 0.9148936170212766
Warm optimizer lr: 0.1
Val acc before epoch 8: 0.9148936170212766
Warm optimizer lr: 0.1
Val acc before epoch 9: 0.9574468085106383
Warm optimizer lr: 0.1
Val acc before epoch 10: 0.925531914893617
Warm optimizer lr: 0.1
Val acc before epoch 11: 0.9148936170212766
Warm optimizer lr: 0.1
Val acc before epoch 12: 0.9148936170212766
Warm optimizer lr: 0.1
Val acc before epoch 13: 0.9468085106382979
Stopping after epoch 14.
Final validation accuracy before push: 94.68085106382979%
Pushing prototypes since finished training
Retraining last layer
	Train acc at iteration 0: 0.4807692307692308
	Train acc at iteration 1: 0.4551282051282051
	Train acc at iteration 2: 0.5128205128205128
	Train acc at iteration 3: 0.592948717948718
	Train acc at iteration 4: 0.5657051282051282
	Train acc at iteration 5: 0.6266025641025641
	Train acc at iteration 6: 0.6730769230769231
	Train acc at iteration 7: 0.6121794871794872
	Train acc at iteration 8: 0.6201923076923077
	Train acc at iteration 9: 0.6634615384615384
	Train acc at iteration 10: 0.6266025641025641
	Train acc at iteration 11: 0.6330128205128205
	Train acc at iteration 12: 0.6410256410256411
	Train acc at iteration 13: 0.6346153846153846
	Train acc at iteration 14: 0.6602564102564102
	Train acc at iteration 15: 0.6618589743589743
	Train acc at iteration 16: 0.6778846153846154
	Train acc at iteration 17: 0.6730769230769231
	Train acc at iteration 18: 0.6698717948717948
	Train acc at iteration 19: 0.6586538461538461
	Train acc at iteration 20: 0.6602564102564102
	Train acc at iteration 21: 0.6266025641025641
	Train acc at iteration 22: 0.657051282051282
	Train acc at iteration 23: 0.6346153846153846
	Train acc at iteration 24: 0.6650641025641025
	Train acc at iteration 25: 0.7147435897435898
	Train acc at iteration 26: 0.6762820512820513
	Train acc at iteration 27: 0.7115384615384616
	Train acc at iteration 28: 0.6987179487179487
	Train acc at iteration 29: 0.7035256410256411
	Train acc at iteration 30: 0.6698717948717948
	Train acc at iteration 31: 0.6987179487179487
	Train acc at iteration 32: 0.7067307692307693
	Train acc at iteration 33: 0.719551282051282
	Train acc at iteration 34: 0.7019230769230769
	Train acc at iteration 35: 0.7211538461538461
	Train acc at iteration 36: 0.717948717948718
	Train acc at iteration 37: 0.7115384615384616
	Train acc at iteration 38: 0.7291666666666666
	Train acc at iteration 39: 0.7483974358974359
	Train acc at iteration 40: 0.7596153846153846
	Train acc at iteration 41: 0.7227564102564102
	Train acc at iteration 42: 0.7131410256410257
	Train acc at iteration 43: 0.7243589743589743
	Train acc at iteration 44: 0.7227564102564102
	Train acc at iteration 45: 0.7612179487179487
	Train acc at iteration 46: 0.7371794871794872
	Train acc at iteration 47: 0.7419871794871795
	Train acc at iteration 48: 0.7628205128205128
	Train acc at iteration 49: 0.7243589743589743
	Train acc at iteration 50: 0.7628205128205128
	Train acc at iteration 51: 0.7371794871794872
	Train acc at iteration 52: 0.7291666666666666
	Train acc at iteration 53: 0.7323717948717948
	Train acc at iteration 54: 0.7387820512820513
	Train acc at iteration 55: 0.7708333333333334
	Train acc at iteration 56: 0.7644230769230769
	Train acc at iteration 57: 0.7483974358974359
	Train acc at iteration 58: 0.7724358974358975
	Train acc at iteration 59: 0.7227564102564102
	Train acc at iteration 60: 0.7339743589743589
	Train acc at iteration 61: 0.7451923076923077
	Train acc at iteration 62: 0.7756410256410257
	Train acc at iteration 63: 0.7403846153846154
	Train acc at iteration 64: 0.7644230769230769
	Train acc at iteration 65: 0.7451923076923077
	Train acc at iteration 66: 0.7419871794871795
	Train acc at iteration 67: 0.7868589743589743
	Train acc at iteration 68: 0.7836538461538461
	Train acc at iteration 69: 0.7692307692307693
	Train acc at iteration 70: 0.780448717948718
	Train acc at iteration 71: 0.7580128205128205
	Train acc at iteration 72: 0.7756410256410257
	Train acc at iteration 73: 0.7596153846153846
	Train acc at iteration 74: 0.7740384615384616
	Train acc at iteration 75: 0.7516025641025641
	Train acc at iteration 76: 0.7660256410256411
	Train acc at iteration 77: 0.7339743589743589
	Train acc at iteration 78: 0.780448717948718
	Train acc at iteration 79: 0.7419871794871795
	Train acc at iteration 80: 0.7596153846153846
	Train acc at iteration 81: 0.7724358974358975
	Train acc at iteration 82: 0.7724358974358975
	Train acc at iteration 83: 0.7772435897435898
	Train acc at iteration 84: 0.7788461538461539
	Train acc at iteration 85: 0.7564102564102564
	Train acc at iteration 86: 0.7788461538461539
	Train acc at iteration 87: 0.7660256410256411
	Train acc at iteration 88: 0.7708333333333334
	Train acc at iteration 89: 0.7403846153846154
	Train acc at iteration 90: 0.7932692307692307
	Train acc at iteration 91: 0.7884615384615384
	Train acc at iteration 92: 0.7724358974358975
	Train acc at iteration 93: 0.7868589743589743
	Train acc at iteration 94: 0.7708333333333334
	Train acc at iteration 95: 0.7948717948717948
	Train acc at iteration 96: 0.7980769230769231
	Train acc at iteration 97: 0.7980769230769231
	Train acc at iteration 98: 0.782051282051282
	Train acc at iteration 99: 0.7708333333333334
	Train acc at iteration 100: 0.7900641025641025
	Train acc at iteration 101: 0.7724358974358975
	Train acc at iteration 102: 0.7772435897435898
	Train acc at iteration 103: 0.7724358974358975
	Train acc at iteration 104: 0.8060897435897436
	Train acc at iteration 105: 0.782051282051282
	Train acc at iteration 106: 0.7964743589743589
	Train acc at iteration 107: 0.8060897435897436
	Train acc at iteration 108: 0.8253205128205128
	Train acc at iteration 109: 0.8044871794871795
	Train acc at iteration 110: 0.7852564102564102
	Train acc at iteration 111: 0.7836538461538461
	Train acc at iteration 112: 0.7852564102564102
	Train acc at iteration 113: 0.7948717948717948
	Train acc at iteration 114: 0.780448717948718
	Train acc at iteration 115: 0.7900641025641025
	Train acc at iteration 116: 0.7644230769230769
	Train acc at iteration 117: 0.7740384615384616
	Train acc at iteration 118: 0.7756410256410257
	Train acc at iteration 119: 0.7916666666666666
	Train acc at iteration 120: 0.8108974358974359
	Train acc at iteration 121: 0.8012820512820513
	Train acc at iteration 122: 0.7852564102564102
	Train acc at iteration 123: 0.7708333333333334
	Train acc at iteration 124: 0.7868589743589743
	Train acc at iteration 125: 0.8125
	Train acc at iteration 126: 0.7900641025641025
	Train acc at iteration 127: 0.8173076923076923
	Train acc at iteration 128: 0.8092948717948718
	Train acc at iteration 129: 0.8028846153846154
	Train acc at iteration 130: 0.7788461538461539
	Train acc at iteration 131: 0.7884615384615384
	Train acc at iteration 132: 0.7900641025641025
	Train acc at iteration 133: 0.7740384615384616
	Train acc at iteration 134: 0.8125
	Train acc at iteration 135: 0.8076923076923077
	Train acc at iteration 136: 0.8205128205128205
	Train acc at iteration 137: 0.8125
	Train acc at iteration 138: 0.8333333333333334
	Train acc at iteration 139: 0.8189102564102564
	Train acc at iteration 140: 0.7948717948717948
	Train acc at iteration 141: 0.7900641025641025
	Train acc at iteration 142: 0.782051282051282
	Train acc at iteration 143: 0.8012820512820513
	Train acc at iteration 144: 0.8028846153846154
	Train acc at iteration 145: 0.7980769230769231
	Train acc at iteration 146: 0.8221153846153846
	Train acc at iteration 147: 0.7980769230769231
	Train acc at iteration 148: 0.8044871794871795
	Train acc at iteration 149: 0.7996794871794872
Getting final validation and test accuracy after training.
Computing and storing results metrics
Final val macro f1-score: 0.6804123711340208
Final val micro accuracy: 0.776595744680851
Final test macro f1-score: 0.4970695970695971
Final test micro accuracy: 0.648936170212766
Final validation:
	Cluster: 0.6338607966899872
	Separation: 0.5321410894393921
Final test:
	Cluster: 0.6030778586864471
	Separation: 0.5296840965747833
Saved Results

Attempting combination 4/6:
prototype_shape: (468, 520, 29)
latent_weight: 0.9
joint_weight_decay: -1
gamma: 0.8
warm_lr_step_size: 100
crs_ent_weight: 1
clst_weight: -9.600000000000001
sep_weight: 2.4
l1_weight: 0.001
warm_ptype_lr: 0.1
last_layer_lr: 0.005
num_warm_epochs: 1000000
push_gap: -1
push_start: 13
num_pushes: 0
last_layer_epochs: 150
joint_lr_step_size: -1
joint_optimizer_lrs: {'features': -1, 'prototype_vectors': -1}



End epoch: 13
Val acc before epoch 0: 0.0
Warm optimizer lr: 0.1
Val acc before epoch 1: 0.40425531914893614
Warm optimizer lr: 0.1
Val acc before epoch 2: 0.7021276595744681
Warm optimizer lr: 0.1
Val acc before epoch 3: 0.7659574468085106
Warm optimizer lr: 0.1
Val acc before epoch 4: 0.8404255319148937
Warm optimizer lr: 0.1
Val acc before epoch 5: 0.8723404255319149
Warm optimizer lr: 0.1
Val acc before epoch 6: 0.9042553191489362
Warm optimizer lr: 0.1
Val acc before epoch 7: 0.9468085106382979
Warm optimizer lr: 0.1
Val acc before epoch 8: 0.9361702127659575
Warm optimizer lr: 0.1
Val acc before epoch 9: 0.8936170212765957
Warm optimizer lr: 0.1
Val acc before epoch 10: 0.925531914893617
Warm optimizer lr: 0.1
Val acc before epoch 11: 0.9361702127659575
Warm optimizer lr: 0.1
Val acc before epoch 12: 0.9468085106382979
Warm optimizer lr: 0.1
Val acc before epoch 13: 0.9361702127659575
Stopping after epoch 14.
Final validation accuracy before push: 93.61702127659575%
Pushing prototypes since finished training
Retraining last layer
	Train acc at iteration 0: 0.6121794871794872
	Train acc at iteration 1: 0.5721153846153846
	Train acc at iteration 2: 0.6394230769230769
	Train acc at iteration 3: 0.7211538461538461
	Train acc at iteration 4: 0.7387820512820513
	Train acc at iteration 5: 0.7259615384615384
	Train acc at iteration 6: 0.7307692307692307
	Train acc at iteration 7: 0.7259615384615384
	Train acc at iteration 8: 0.7403846153846154
	Train acc at iteration 9: 0.7676282051282052
	Train acc at iteration 10: 0.75
	Train acc at iteration 11: 0.7419871794871795
	Train acc at iteration 12: 0.7564102564102564
	Train acc at iteration 13: 0.7548076923076923
	Train acc at iteration 14: 0.7451923076923077
	Train acc at iteration 15: 0.7435897435897436
	Train acc at iteration 16: 0.7163461538461539
	Train acc at iteration 17: 0.7307692307692307
	Train acc at iteration 18: 0.7532051282051282
	Train acc at iteration 19: 0.7756410256410257
	Train acc at iteration 20: 0.7580128205128205
	Train acc at iteration 21: 0.75
	Train acc at iteration 22: 0.717948717948718
	Train acc at iteration 23: 0.7580128205128205
	Train acc at iteration 24: 0.7435897435897436
	Train acc at iteration 25: 0.7756410256410257
	Train acc at iteration 26: 0.7355769230769231
	Train acc at iteration 27: 0.7628205128205128
	Train acc at iteration 28: 0.7788461538461539
	Train acc at iteration 29: 0.7532051282051282
	Train acc at iteration 30: 0.75
	Train acc at iteration 31: 0.7628205128205128
	Train acc at iteration 32: 0.7532051282051282
	Train acc at iteration 33: 0.7676282051282052
	Train acc at iteration 34: 0.7387820512820513
	Train acc at iteration 35: 0.7243589743589743
	Train acc at iteration 36: 0.7387820512820513
	Train acc at iteration 37: 0.7516025641025641
	Train acc at iteration 38: 0.7532051282051282
	Train acc at iteration 39: 0.7612179487179487
	Train acc at iteration 40: 0.7323717948717948
	Train acc at iteration 41: 0.7451923076923077
	Train acc at iteration 42: 0.7644230769230769
	Train acc at iteration 43: 0.7355769230769231
	Train acc at iteration 44: 0.7900641025641025
	Train acc at iteration 45: 0.7532051282051282
	Train acc at iteration 46: 0.7660256410256411
	Train acc at iteration 47: 0.7548076923076923
	Train acc at iteration 48: 0.7788461538461539
	Train acc at iteration 49: 0.7724358974358975
	Train acc at iteration 50: 0.7612179487179487
	Train acc at iteration 51: 0.7596153846153846
	Train acc at iteration 52: 0.7644230769230769
	Train acc at iteration 53: 0.7243589743589743
	Train acc at iteration 54: 0.7580128205128205
	Train acc at iteration 55: 0.7884615384615384
	Train acc at iteration 56: 0.7724358974358975
	Train acc at iteration 57: 0.7596153846153846
	Train acc at iteration 58: 0.7676282051282052
	Train acc at iteration 59: 0.7788461538461539
	Train acc at iteration 60: 0.7788461538461539
	Train acc at iteration 61: 0.7692307692307693
	Train acc at iteration 62: 0.7467948717948718
	Train acc at iteration 63: 0.7788461538461539
	Train acc at iteration 64: 0.7676282051282052
	Train acc at iteration 65: 0.7916666666666666
	Train acc at iteration 66: 0.7467948717948718
	Train acc at iteration 67: 0.7740384615384616
	Train acc at iteration 68: 0.7660256410256411
	Train acc at iteration 69: 0.7644230769230769
	Train acc at iteration 70: 0.7676282051282052
	Train acc at iteration 71: 0.782051282051282
	Train acc at iteration 72: 0.7836538461538461
	Train acc at iteration 73: 0.7628205128205128
	Train acc at iteration 74: 0.7692307692307693
	Train acc at iteration 75: 0.7900641025641025
	Train acc at iteration 76: 0.7740384615384616
	Train acc at iteration 77: 0.7724358974358975
	Train acc at iteration 78: 0.782051282051282
	Train acc at iteration 79: 0.7451923076923077
	Train acc at iteration 80: 0.7612179487179487
	Train acc at iteration 81: 0.7900641025641025
	Train acc at iteration 82: 0.7708333333333334
	Train acc at iteration 83: 0.7852564102564102
	Train acc at iteration 84: 0.7788461538461539
	Train acc at iteration 85: 0.7868589743589743
	Train acc at iteration 86: 0.7868589743589743
	Train acc at iteration 87: 0.7724358974358975
	Train acc at iteration 88: 0.7772435897435898
	Train acc at iteration 89: 0.7708333333333334
	Train acc at iteration 90: 0.7996794871794872
	Train acc at iteration 91: 0.8157051282051282
	Train acc at iteration 92: 0.7708333333333334
	Train acc at iteration 93: 0.7852564102564102
	Train acc at iteration 94: 0.8044871794871795
	Train acc at iteration 95: 0.7628205128205128
	Train acc at iteration 96: 0.7980769230769231
	Train acc at iteration 97: 0.8012820512820513
	Train acc at iteration 98: 0.780448717948718
	Train acc at iteration 99: 0.7724358974358975
	Train acc at iteration 100: 0.7900641025641025
	Train acc at iteration 101: 0.7948717948717948
	Train acc at iteration 102: 0.7884615384615384
	Train acc at iteration 103: 0.7628205128205128
	Train acc at iteration 104: 0.7596153846153846
	Train acc at iteration 105: 0.782051282051282
	Train acc at iteration 106: 0.7708333333333334
	Train acc at iteration 107: 0.7932692307692307
	Train acc at iteration 108: 0.7980769230769231
	Train acc at iteration 109: 0.7916666666666666
	Train acc at iteration 110: 0.7836538461538461
	Train acc at iteration 111: 0.7692307692307693
	Train acc at iteration 112: 0.7884615384615384
	Train acc at iteration 113: 0.7580128205128205
	Train acc at iteration 114: 0.7852564102564102
	Train acc at iteration 115: 0.7772435897435898
	Train acc at iteration 116: 0.7756410256410257
	Train acc at iteration 117: 0.780448717948718
	Train acc at iteration 118: 0.7756410256410257
	Train acc at iteration 119: 0.8173076923076923
	Train acc at iteration 120: 0.7964743589743589
	Train acc at iteration 121: 0.7708333333333334
	Train acc at iteration 122: 0.8076923076923077
	Train acc at iteration 123: 0.7980769230769231
	Train acc at iteration 124: 0.8108974358974359
	Train acc at iteration 125: 0.7788461538461539
	Train acc at iteration 126: 0.7628205128205128
	Train acc at iteration 127: 0.8141025641025641
	Train acc at iteration 128: 0.8012820512820513
	Train acc at iteration 129: 0.7932692307692307
	Train acc at iteration 130: 0.780448717948718
	Train acc at iteration 131: 0.8044871794871795
	Train acc at iteration 132: 0.7884615384615384
	Train acc at iteration 133: 0.7884615384615384
	Train acc at iteration 134: 0.7836538461538461
	Train acc at iteration 135: 0.7852564102564102
	Train acc at iteration 136: 0.8028846153846154
	Train acc at iteration 137: 0.8157051282051282
	Train acc at iteration 138: 0.7692307692307693
	Train acc at iteration 139: 0.7756410256410257
	Train acc at iteration 140: 0.7964743589743589
	Train acc at iteration 141: 0.7836538461538461
	Train acc at iteration 142: 0.7980769230769231
	Train acc at iteration 143: 0.7948717948717948
	Train acc at iteration 144: 0.7900641025641025
	Train acc at iteration 145: 0.7852564102564102
	Train acc at iteration 146: 0.7884615384615384
	Train acc at iteration 147: 0.7916666666666666
	Train acc at iteration 148: 0.7980769230769231
	Train acc at iteration 149: 0.7788461538461539
Getting final validation and test accuracy after training.
Computing and storing results metrics
Final val macro f1-score: 0.49346405228758167
Final val micro accuracy: 0.6063829787234043
Final test macro f1-score: 0.5728395061728395
Final test micro accuracy: 0.6595744680851063
Final validation:
	Cluster: 0.6127162277698517
	Separation: 0.5283258557319641
Final test:
	Cluster: 0.6150453388690948
	Separation: 0.5303075611591339
Saved Results

Attempting combination 5/6:
prototype_shape: (468, 520, 29)
latent_weight: 0.9
joint_weight_decay: -1
gamma: 0.8
warm_lr_step_size: 100
crs_ent_weight: 1
clst_weight: -9.600000000000001
sep_weight: 2.4
l1_weight: 0.001
warm_ptype_lr: 0.1
last_layer_lr: 0.001
num_warm_epochs: 1000000
push_gap: -1
push_start: 13
num_pushes: 0
last_layer_epochs: 150
joint_lr_step_size: -1
joint_optimizer_lrs: {'features': -1, 'prototype_vectors': -1}



End epoch: 13
Val acc before epoch 0: 0.0
Warm optimizer lr: 0.1
Val acc before epoch 1: 0.3723404255319149
Warm optimizer lr: 0.1
Val acc before epoch 2: 0.7127659574468085
Warm optimizer lr: 0.1
Val acc before epoch 3: 0.7659574468085106
Warm optimizer lr: 0.1
Val acc before epoch 4: 0.8829787234042553
Warm optimizer lr: 0.1
Val acc before epoch 5: 0.8936170212765957
Warm optimizer lr: 0.1
Val acc before epoch 6: 0.925531914893617
Warm optimizer lr: 0.1
Val acc before epoch 7: 0.9042553191489362
Warm optimizer lr: 0.1
Val acc before epoch 8: 0.9361702127659575
Warm optimizer lr: 0.1
Val acc before epoch 9: 0.9361702127659575
Warm optimizer lr: 0.1
Val acc before epoch 10: 0.9574468085106383
Warm optimizer lr: 0.1
Val acc before epoch 11: 0.925531914893617
Warm optimizer lr: 0.1
Val acc before epoch 12: 0.9468085106382979
Warm optimizer lr: 0.1
Val acc before epoch 13: 0.925531914893617
Stopping after epoch 14.
Final validation accuracy before push: 92.5531914893617%
Pushing prototypes since finished training
Retraining last layer
	Train acc at iteration 0: 0.7660256410256411
	Train acc at iteration 1: 0.7980769230769231
	Train acc at iteration 2: 0.7740384615384616
	Train acc at iteration 3: 0.7836538461538461
	Train acc at iteration 4: 0.7868589743589743
	Train acc at iteration 5: 0.7788461538461539
	Train acc at iteration 6: 0.7740384615384616
	Train acc at iteration 7: 0.8028846153846154
	Train acc at iteration 8: 0.8189102564102564
	Train acc at iteration 9: 0.7948717948717948
	Train acc at iteration 10: 0.7836538461538461
	Train acc at iteration 11: 0.7932692307692307
	Train acc at iteration 12: 0.8108974358974359
	Train acc at iteration 13: 0.7756410256410257
	Train acc at iteration 14: 0.7852564102564102
	Train acc at iteration 15: 0.8076923076923077
	Train acc at iteration 16: 0.8157051282051282
	Train acc at iteration 17: 0.7852564102564102
	Train acc at iteration 18: 0.7948717948717948
	Train acc at iteration 19: 0.8221153846153846
	Train acc at iteration 20: 0.8125
	Train acc at iteration 21: 0.8108974358974359
	Train acc at iteration 22: 0.8125
	Train acc at iteration 23: 0.8108974358974359
	Train acc at iteration 24: 0.780448717948718
	Train acc at iteration 25: 0.8269230769230769
	Train acc at iteration 26: 0.8060897435897436
	Train acc at iteration 27: 0.8365384615384616
	Train acc at iteration 28: 0.8189102564102564
	Train acc at iteration 29: 0.8092948717948718
	Train acc at iteration 30: 0.8541666666666666
	Train acc at iteration 31: 0.8237179487179487
	Train acc at iteration 32: 0.8205128205128205
	Train acc at iteration 33: 0.8317307692307693
	Train acc at iteration 34: 0.8237179487179487
	Train acc at iteration 35: 0.7868589743589743
	Train acc at iteration 36: 0.8237179487179487
	Train acc at iteration 37: 0.8108974358974359
	Train acc at iteration 38: 0.8301282051282052
	Train acc at iteration 39: 0.8269230769230769
	Train acc at iteration 40: 0.8237179487179487
	Train acc at iteration 41: 0.8397435897435898
	Train acc at iteration 42: 0.842948717948718
	Train acc at iteration 43: 0.8221153846153846
	Train acc at iteration 44: 0.7948717948717948
	Train acc at iteration 45: 0.8076923076923077
	Train acc at iteration 46: 0.8493589743589743
	Train acc at iteration 47: 0.8141025641025641
	Train acc at iteration 48: 0.8413461538461539
	Train acc at iteration 49: 0.8028846153846154
	Train acc at iteration 50: 0.8044871794871795
	Train acc at iteration 51: 0.7788461538461539
	Train acc at iteration 52: 0.842948717948718
	Train acc at iteration 53: 0.8221153846153846
	Train acc at iteration 54: 0.8205128205128205
	Train acc at iteration 55: 0.8189102564102564
	Train acc at iteration 56: 0.7980769230769231
	Train acc at iteration 57: 0.8317307692307693
	Train acc at iteration 58: 0.8333333333333334
	Train acc at iteration 59: 0.8253205128205128
	Train acc at iteration 60: 0.8317307692307693
	Train acc at iteration 61: 0.8157051282051282
	Train acc at iteration 62: 0.7996794871794872
	Train acc at iteration 63: 0.8253205128205128
	Train acc at iteration 64: 0.8221153846153846
	Train acc at iteration 65: 0.8269230769230769
	Train acc at iteration 66: 0.8269230769230769
	Train acc at iteration 67: 0.8237179487179487
	Train acc at iteration 68: 0.8012820512820513
	Train acc at iteration 69: 0.8285256410256411
	Train acc at iteration 70: 0.8493589743589743
	Train acc at iteration 71: 0.8349358974358975
	Train acc at iteration 72: 0.8285256410256411
	Train acc at iteration 73: 0.7868589743589743
	Train acc at iteration 74: 0.8237179487179487
	Train acc at iteration 75: 0.8301282051282052
	Train acc at iteration 76: 0.8253205128205128
	Train acc at iteration 77: 0.8349358974358975
	Train acc at iteration 78: 0.8189102564102564
	Train acc at iteration 79: 0.8092948717948718
	Train acc at iteration 80: 0.8397435897435898
	Train acc at iteration 81: 0.8461538461538461
	Train acc at iteration 82: 0.8317307692307693
	Train acc at iteration 83: 0.8461538461538461
	Train acc at iteration 84: 0.8349358974358975
	Train acc at iteration 85: 0.8269230769230769
	Train acc at iteration 86: 0.8221153846153846
	Train acc at iteration 87: 0.8381410256410257
	Train acc at iteration 88: 0.8349358974358975
	Train acc at iteration 89: 0.842948717948718
	Train acc at iteration 90: 0.8205128205128205
	Train acc at iteration 91: 0.8221153846153846
	Train acc at iteration 92: 0.8317307692307693
	Train acc at iteration 93: 0.8028846153846154
	Train acc at iteration 94: 0.8253205128205128
	Train acc at iteration 95: 0.8317307692307693
	Train acc at iteration 96: 0.8413461538461539
	Train acc at iteration 97: 0.8253205128205128
	Train acc at iteration 98: 0.8221153846153846
	Train acc at iteration 99: 0.8253205128205128
	Train acc at iteration 100: 0.8253205128205128
	Train acc at iteration 101: 0.8397435897435898
	Train acc at iteration 102: 0.8573717948717948
	Train acc at iteration 103: 0.8044871794871795
	Train acc at iteration 104: 0.8333333333333334
	Train acc at iteration 105: 0.8509615384615384
	Train acc at iteration 106: 0.8349358974358975
	Train acc at iteration 107: 0.8092948717948718
	Train acc at iteration 108: 0.8317307692307693
	Train acc at iteration 109: 0.8333333333333334
	Train acc at iteration 110: 0.842948717948718
	Train acc at iteration 111: 0.8285256410256411
	Train acc at iteration 112: 0.8381410256410257
	Train acc at iteration 113: 0.8365384615384616
	Train acc at iteration 114: 0.8173076923076923
	Train acc at iteration 115: 0.8285256410256411
	Train acc at iteration 116: 0.8365384615384616
	Train acc at iteration 117: 0.8221153846153846
	Train acc at iteration 118: 0.8365384615384616
	Train acc at iteration 119: 0.8157051282051282
	Train acc at iteration 120: 0.8301282051282052
	Train acc at iteration 121: 0.8365384615384616
	Train acc at iteration 122: 0.8381410256410257
	Train acc at iteration 123: 0.8541666666666666
	Train acc at iteration 124: 0.8221153846153846
	Train acc at iteration 125: 0.8509615384615384
	Train acc at iteration 126: 0.8333333333333334
	Train acc at iteration 127: 0.8253205128205128
	Train acc at iteration 128: 0.8525641025641025
	Train acc at iteration 129: 0.8237179487179487
	Train acc at iteration 130: 0.842948717948718
	Train acc at iteration 131: 0.8413461538461539
	Train acc at iteration 132: 0.8237179487179487
	Train acc at iteration 133: 0.8333333333333334
	Train acc at iteration 134: 0.8301282051282052
	Train acc at iteration 135: 0.8477564102564102
	Train acc at iteration 136: 0.842948717948718
	Train acc at iteration 137: 0.8157051282051282
	Train acc at iteration 138: 0.8461538461538461
	Train acc at iteration 139: 0.8173076923076923
	Train acc at iteration 140: 0.8509615384615384
	Train acc at iteration 141: 0.8413461538461539
	Train acc at iteration 142: 0.8269230769230769
	Train acc at iteration 143: 0.8141025641025641
	Train acc at iteration 144: 0.8461538461538461
	Train acc at iteration 145: 0.8189102564102564
	Train acc at iteration 146: 0.8509615384615384
	Train acc at iteration 147: 0.8333333333333334
	Train acc at iteration 148: 0.8509615384615384
	Train acc at iteration 149: 0.8573717948717948
Getting final validation and test accuracy after training.
Computing and storing results metrics
Final val macro f1-score: 0.6603508771929825
Final val micro accuracy: 0.7446808510638298
Final test macro f1-score: 0.5875968992248062
Final test micro accuracy: 0.7021276595744681
Final validation:
	Cluster: 0.6222141087055206
	Separation: 0.5334477722644806
Final test:
	Cluster: 0.59766685962677
	Separation: 0.5219409167766571
Saved Results
Finished search.
